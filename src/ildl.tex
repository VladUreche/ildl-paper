\section{Ad-hoc Representation Transformation}
\label{sec:ildl}

This section presents the Ad-hoc Data Representation Transformation, which is based on the global, all-or-nothing Late Data Layout (LDL) transformation mechanism, extended with the necessary features to allow ad-hoc programmer-driven transformations.

% DRT - when the data has more than one representation - generally, the representation can be either more flexible or more efficient
Data can usually be represented in several ways, some more efficient and others more flexible. For example, integer numbers can use either the primitive (unboxed) value encoding, which is more efficient, or the object-based (boxed) encoding, which is more flexible. The boxed representation allows integers to act as the receivers of dynamically dispatched method calls, to be assigned to supertypes and to instantiate erased generics. However, the extra flexibility comes at a price: boxed integers are allocated on the heap so they need to be garbage-collected later. Also, all the operations on boxed integers incur an indirection overhead, leading to a tension between the two representations.

% From the language perspective: Expose this difference vs transform in the compiler
From a language perspective, there are two approaches to exposing the multiple representations of a type: either have a different (and incompatible) type for each representation, as Java does, or hide the difference and present a single high-level type, as ML, Haskell and Scala do. Either way, the final low-level bytecode or assembly code needs to handle the two representations separately, since they correspond to very different entities: references and values.

% DRTs- two steps: decide on the representation of each value and introduce coercions
% Choosing the representation -- simple, but mind the generics -- for our case, we need to select the values
Exposing a single high-level type in the language is more popular among programmers for its simplicity, but it puts more burden on the compiler, which has to do two additional steps: first, it needs to choose the data representation of each value and second, it needs to introduce coercions that switch between representations where necessary. For example, since only boxed integers can instantiate generics, any unboxed integer going into a generic container, such as a list, needs to be converted to the boxed representation. This work is done in the compiler pipeline, in so-called data representation transformations.

% Introducing LDL
The next section will present the Late Data Layout mechanism, a general data representation technique and the three properties that make it best suited for the Ad-hoc Data Representation Transformation: selectivity, optimality and consistency.

\subsection {Late Data Layout}

The Late Data Layout (LDL) mechanism is the underlying transformation used in Scala to unbox primitive types, to implement value class inlining and to specialize classes using the miniboxed encoding. It is a flexible and reliable mechanism, tested on many thousands of lines of code. % making it a good starting point for other data representation transformations. % This chapter will present the LDL mechanism in detail.

% In this context, Late data laout was chosen for its ability to selectivity pick values to be transformed and the optimality in introducing coercions
LDL allows selectively picking the representation for each value and automatically introduces the necessary coercions in a consistent and optimal way. Selectively choosing the representation of each value can be done either by the programmer, through annotations or by the compiler, based on predefined rules.

% What does it do? Starting from a high-level type (or concept), such as |scala.Int|, it transforms all references to low-level representations
Using LDL, a language can expose high-level types (called high-level concepts in the LDL terminology), such as the integer type exposed by Scala, |Int|, which can represent either a boxed or unboxed value in the low-level bytecode. In the following example, we have values of types |Int| and |Any|, where |Any| is the top of the Scala type system, and thus a supertype of |Int|:

\begin{lstlisting-nobreak}
val i: Int = 1
val j: Int = i
val k: Any = j
\end{lstlisting-nobreak}

Since Scala compiles down to Java bytecode, during compilation, the LDL-based primitive unboxing transformation bridges the gap between the high-level |Int| concept and its two representations: the unboxed |int| and the boxed |java.lang.Integer| representation. Along the way, it introduces the necessary coercions between these two representations. For example, the code above is translated to:

\begin{lstlisting-nobreak}
val i: `int` = 1
val j: `int` = i
val k: Any = Integer.valueOf(j)
\end{lstlisting-nobreak}

%How does LDL work? -- injects representation information in the types and uses them to introduce coercions
%3 phases: Inject, Coerce, Commit.
The LDL mechanism transforms the data representation in three phases: \inject{}, \coerce{} and \commit{}. Each of the phases is responsible for a property of the transformation: \inject{} makes LDL selective, \coerce{} makes it optimal and \commit{} makes it consistent. In our examples, we show the equivalent source code for the program abstract syntax trees (ASTs) after each of these phases.

% Inject
\subsubsection{The \inject{} phase} is responsible for marking each value with its desired representation. In the case of primitive integer unboxing, the annotation is |@unboxed|, and it signals a value should be stored in the unboxed |int| representation. As an optimization, instead of adding another |@boxed| annotation, values that are not marked are automatically considered as boxed. Following the \inject{} phase, the previous example will be transformed to:

\begin{lstlisting-nobreak}
val i: `@unboxed` Int = 1 // Int can be unboxed => add @unboxed annotation
val j: `@unboxed` Int = i // Int can be unboxed => add @unboxed annotation
val k: Any = j                  // Any cannot be unboxed => requires boxed value
\end{lstlisting-nobreak}

The \inject{} phase gives LDL the selective nature, allowing it to mark each individual value with its representation. For example, it would have been equally correct if the marking rules decided that |j| should be boxed, in which case its type would not have been marked. One of the tricks employed by the LDL transformation is that, during the \inject{} phase boxed and unboxed values are still compatible, so there is no need for coercions.

% Coerce
\subsubsection{The \coerce{} phase,} as its name suggests, introduces coercions. This is done by changing the annotation semantics: annotated types become incompatible among themselves and with their un-annotated counterparts. This change in the annotation semantics corresponds to introducing the different representations: each annotation corresponds to a representation, and representations are not compatible with each other. With this change, an assignment from one representation to another will have mismatching types. Therefore, by re-type-checking the tree, the \coerce{} phase can detect representation mismatches and can patch them using coercions. In the example, the last line contains such a mismatch:

\begin{lstlisting-nobreak}
val i: @unboxed Int = 1 // expected: @unboxed, found: @unboxed
val j: @unboxed Int = i // expected: @unboxed, found: @unboxed
val k: Any = `box`(j)             // expected:  <@boxed>, found: @unboxed => box value
\end{lstlisting-nobreak}

The \coerce{} phase brings the optimal nature of the LDL transformation. Instead of explaining how this is achieved, we will use an example to show what optimality means. Given the following two definitions:

\begin{lstlisting-nobreak}
val c: Boolean = ...
val l1: @unboxed Int = if (c) i else j
val l2: @unboxed Int = `unbox`(if (c) `box`(i) else `box`(j)
\end{lstlisting-nobreak}

It is clear that the two definitions will always produce the same result. Still, the first one is markedly better: it does not execute any coercions, compared to second definition, which executes 2 coercions regardless of the value of |c|. These subtle sub-optimalities can slow down the program the execution, increase the heap footprint and the bytecode size. This is why the \coerce{} phase needs to optimal. The LDL paper \cite{ldl} makes the following (intuition-based but not proven) claim: in any given terminating execution trace through the transformed  program, the number of coercions executed is minimal, modulo the annotations introduced by the \inject{} phase and the transformations in the \commit{} phase. What this means, for us, is that given a set of annotations, we're guaranteed the \coerce{} phase will introduce the minimum overhead.

% Commit
\subsubsection{The \commit{} phase} is responsible for introducing the actual representations. In the case of primitive unboxing, |@unboxed Int| is replaced by |int| and |Int|, which is considered boxed, is replaced by |java.lang.Integer|. The |box| and |unbox| coercions are also replaced by the creation of objects and, respectively, by the extraction of the unboxed value.

\begin{lstlisting-nobreak}
val i: `int` = 1
vla j: `int` = i
val k: Any = `Integer.valueOf`(j)
\end{lstlisting-nobreak}

The \commit{} phase is responsible for the consistency of the transformation. Since the program abstract syntax tree (AST) has been checked by the type-system extended with representation semantics, the \commit{} phase is guaranteed to correctly handle the value representations and to correctly coerce between them. This allows the \commit{} phase to be a very simple, syntax-based, transformation over the program abstract syntax tree (AST).

% Object-oriented support
\subsubsection{Object-Oriented Patterns.}

Aside from introducing coercions, data representation transformations must handle object-oriented patterns, such as method calls and subtyping. Not all representations can be used with these patterns, such as, for example, calling the |toString| method on the unboxed |int| representation:

\begin{lstlisting-nobreak}
val a: `@unboxed Int` = 1
println(a.toString)
\end{lstlisting-nobreak}

Fortunately, LDL allows the transformations to handle these cases with ease: by assigning the non-annotated type to the most flexible representation and requiring the method call receivers to have non-annotated types, LDL makes it easy to correctly handle object-oriented patterns. In the case of calling the |toString| method, the |@unboxed Int| receiver will be boxed, so it can act as the receiver of the method call. Subtyping is handled in a similar fashion, by requiring the most flexible representation:

\begin{lstlisting-nobreak}
val a: @unboxed Int = 1
println(`box`(a).toString)
\end{lstlisting-nobreak}

To improve performance, the LDL mechanism also supports extension methods. For example, if the |extension_toString| method is available for the unboxed |int| representation, there is no need to convert it to the boxed representation just to call |toString| on it. Instead, the call takes place without a representation conversion:

\begin{lstlisting-nobreak}
val a: @unboxed Int = 1
println(`extension_toString`(a))
\end{lstlisting-nobreak}

% Limited code scopes
\subsubsection{Support for Generics.}
The Late Data Layout mechanism is agnostic to generics. This means that, depending on the transformation semantics and the implementation of generics, the mechanism can inject annotations in the type arguments or not. For example, if generics are erased, a list of integers will have type |List[Int]|, since values need to be boxed. If generics are unboxed and reified, the list type will be |List[@unboxed Int]|. In the original paper \cite{ldl}, the authors show examples of both cases, where annotations are propagated inside generics and when they are not, showing how the LDL mechanism adapts seamlessly to either case.

Having seen the Late Data Layout mechanism at work for unboxing primitive types, we can now look at how it can be extended to handle ad-hoc programmer-driven data representation transformations.

\subsection{Ad-hoc Data Representation Transformation}

% DEFINE WHAT WE WANT
%  - transform scopes of code, where the scope can contain anything from an expression to a method or class definition
The goal of the ADR transformation is to relax two constraints from previous data representation transformations: first, allow the transformation to take place for limited scopes, ranging from an expression all the way to complete class or package definitions and to allow custom, programmer-defined alternative representations.

Unfortunately, relaxing these two constraints breaks core invariants of the LDL transformation. The following sections will present these invariants and explain how the ART transformation restores and preserves them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Persisting the Data Representation Information}
\label{sec:ildl:signatures}

%  - make sure that separate compilation still works (e.g: code can be called from a separately compiled source)
Relaxing the global, all-or-nothing nature of LDL and allowing it to be limited to scopes breaks one of its core invariants: the fact that, throughout separate compilations, method and field signatures transform according to the same (context-free) rules, therefore yielding consistent object layouts. This means that, knowing a method's high-level signature, based on the high-level concept (for example |Int|), we can unambiguously determine the low-level signature. For example the method:

\begin{lstlisting-nobreak}
def valueAtIndex(lst: List[Int], idx: Int) = ...
\end{lstlisting-nobreak}

Will always be compiled to the low-level bytecode signature:

\begin{lstlisting-nobreak}
def valueAtIndex(lst: List[`java.lang.Integer`], idx: `int`) = ...
\end{lstlisting-nobreak}

This makes it possible to call methods already lowered to bytecode in previous compilation sessions without the risk of their signature not matching the expected signature.

%  - correctness: make sure that we can't make any calls that are not according to the type system
However, when limiting the data representation transformation to a scope, we could, for example, only include its definition. Let us return to our example:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = ...
}
\end{lstlisting-nobreak}

In this case, the low-level signature for the |gcd| method would be:

\begin{lstlisting-nobreak}
def gcd(n1: `long`, n2: `long`): `long` = ...
\end{lstlisting-nobreak}

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)
If, in the bytecode, we stored the high-level method signature, using pairs of integers, a separate compilation would not be aware of the data representation transformation that occurred, so it might pass two pairs of integers on the stack, which would break the low-level execution. On the other hand, if the separate compilation would look at both the high-level and low-level signatures, one taken from the class file metadata and the one from the actual bytecode, it would notice a discrepancy: the pair of integer arguments from the high-level code somehow transformed into unboxed long integer arguments. But this would still be insufficient to call the method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Global vs local/ad-hoc -- relationship between LDL and iLDL + separate compilation
% Where does the transformation take place -- difference between high-level signatures and low-level signatures \ldots
How can the pairs of integers be transformed into long integers in a separate compilation, which is not aware of the ADRT transformation semantics? The separate compilation would not be aware of the |IntPairComplexToLongComplex| object, which handles the transformations. Therefore, even looking at both the high-level and low-level signatures is not enough, as the separate compilation is missing the semantic link between the two data representations.

To solve this problem, we need to first annotate the values using that will be transformed, in a phase similar to the LDL \inject{} phase:

\begin{lstlisting-nobreak}
def gcd(
    n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
    n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
  ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = ...
\end{lstlisting-nobreak}

The key to limiting the ADR transformation to a scope is \textbf{persisiting the high-level signature with the ADRT annotation} in the bytecode, along with the low-level method bytecode. This allows a future separate compilation stage to derive two critical pieces of information about the |gcd| method:

\begin{itemize}
  \item its low-level signature, based on the transformation description object, \\ |IntPairComplexToLongComplex|, which contains both the high-level type, |(Int, Int)| and its representation, |Long|;
  \item the transformation necessary when calling the |gcd| method from a non-transformed scope.
\end{itemize}

Knowing this critical piece of information, we can use the LDL transformation on the call to |gcd| made in a different separate compilation stage:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Injection -- before storing signatures, bridge, coerce and commit come later.
During the type-checking and the \inject{} phase, the high-level signature for |gcd| would be loaded from the bytecode and the call would be type-checked against the loaded signature. Remember that, before the \coerce{} phase, annotated types are compatible among themselves and with non-annotated types:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(
//      n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
//      n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
//    ): `@repr(IntPairComplexToLongComplex)` (Int, Int)
val res: (Int, Int) =
  gcd(
    (55, 2),   // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
    (17, 13)  // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
  )             // expexted: (Int, Int) found: @repr(...) (Int, Int) => okay
\end{lstlisting-nobreak}

During the \coerce{} phase, re-type-checking the tree will introduce coercions where annotated types and non-annotated types mismatch. It is important that the coercions carry the transformation description object:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  fromRepr(IntPairComplexToLongComplex, gcd(
    toRepr(IntPairComplexToLongComplex, (55, 2)),
    toRepr(IntPairComplexToLongComplex, (17, 13)
  ))
\end{lstlisting-nobreak}

Finally, during the \commit{} phase, the encoding and decoding methods from the transformation description object are used:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  IntPairComplexToLongComplex.fromRepr(gcd(
    IntPairComplexToLongComplex.toRepr((55, 2)),
    IntPairComplexToLongComplex.toRepr((17, 13))
  ))
\end{lstlisting-nobreak}

This concludes the explanation of the signature persistence problem. The following paragraphs will explain a series of corner cases and interactions of the ADR transformation.

\subsubsection{Corner Cases and Interactions}

\subsubsection{Tracking the Transformed Values}
% Persisting the transformation decisions = persisting annotations
%  -- Usage across compilations
%  -- Tracking the transformer
%  -- interoperating between ``islands'' of modified code
%      -- using the same encoding
%      -- using different encodings
This allows inserting coercions.
 -- the rippling effect of signature transformations: keep track of transformer!

\subsubsection{Two Types, One Representation}

What if we have two types that erase to the same representation? Could a method where the first type, say (Int, Int) was converted to long be called by code that was encoding |(Float, Float)| as a long integer, thus compromising the semantics of the language?

The answer is no, since the type system protects us from doing this. The annotations, before the coerce phase, only bear the final representation, but the type exposed is the high-level type, not the representation. Therefore, the error message would make it very clear that the code attempted to call a method accepting a pair of integers but passed a pair of floating-point numbers.

\subsubsection{One Type, One Representation, Compatibility}

Another question we may ask ourselves is what we have the |ildl| marker method called from two different locations with the same transformation description object? Would they need to convert to the high-level (and inefficient type)? The answer is no, since the method signature will have the high-level type annotated with the representation, which will match the arguments for the call.

\subsubsection{One Type, Two Representations}

Finally, a third question one may ask is what if we had a single type, such as |GaussianInteger|, which could be represented as either |(Int, Int)| or |Long|, and attempted to call between parts of the code using the two representations. The answer is that, keeping the high-level signature would allow the ildl transformation to know that it needs to convert from one representation to another: it would first decode the first representation to expose the high-level type, which it would then re-encode with the second representation.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Handling Generics and The Object Model}
\label{sec:ildl:generics}


% 2 Aspects \ldots
\subsubsection{Generics}
%  - handle generics and the object model correctly

% Generics
%  -- Nesting datastructures
Can we transform |List[(Int, Int)]| into |List[Long]|. In the general case, no, for two reasons:
\begin{itemize}
  \item since it could break aliasing (for mutable data structures)
  \item since there is no method available to transform from one representation to the other
\end{itemize}

Solution: we could either add methods for transforming data structures in the transformation description object or, if there is no such method available, the correctness-preserving approach is not to transform the representation inside generics.


\subsubsection{The Object Model: Subtyping and Overriding}
% Overriding - introduce an additional phase in LDL: bridge
We add bridges, therefore the ILDL transformation has four phases instead of three: inject, bridge, coerce and commit.

How do you override a class with a transformed method?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preserving the Semantics}
\label{sec:ildl:semantics}

%  - for performance reasons we want to have something like LDL's extension methods

% Semantics changes
\subsubsection{Methods and Operators of the Object}
% Operators
%  -- transformation tracker
We can always decode the representation to expose the high-level type and make the call based on that. Yet, this is inefficient. The solution is to short-circuit the calls to the operators and perform them directly on the encoded value, much like extension methods work for value classes.

Short-cutting methods are located in the transformation description object, which needs to contain:
\begin{itemize}
  \item transformations between the high-level type and the representation (and back);
  \item (optional) transformations between generic containers with the high-level type (|List[(Int, Int)]|) and the generic container with the improved representation (|List[Long]|);
  \item (optional) operators and methods on the encoded representation, such as |+|, |-|, |*|, |/|, |%| and |norm|.
\end{itemize}

Operators need not required their arguments to use the high-level type: for example, when defining the |+| operator, we need to force the second operator to use the high-level type |(Int, Int)|. Instead, we accept a value of type |@encoded Long|, which allows it to accept the optimized representation for the other value as well. Interestingly, this does not prevent it from accepting the high-level type |(Int, Int)|: based on annotations, the ildl transformation knows the |(Int, Int)| value must be converted to a |Long| value.

\subsubsection{Semantics of the Transformed Type}
%  -- Liskov substitution principle
reviewers may argue that data containers are generic and flexible in order to ease evolution of the data structures. Therefore transforming non-final containers might lose their semantics, since we fix the semantics of operators, which otherwise would have been dynamically dispatched to the most specific implementation. But that can be argued against using the Liskov principle -- if a subclass of the container modifies the behavior of an operator, even the original program's semantics may now be incorrect, therefore our transformation won't make correctness worse. Therefore, according to the Liskov principle, as long as the updated (static) operators are semantically equivalent to the data container's, the transformation will not affect the program semantics.

