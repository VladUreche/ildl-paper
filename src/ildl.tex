\section{Incremental Late Data Layout}
\label{sec:ildl}
\begin{itemize}
  \item theory of ldl - data representation transformation - coercions, optimality
  \item injection + signatures, persistence
\end{itemize}

% Executive summary + vision
This section will explain the end goal of our transformation and will expose its core: the data representation transformation. We will first present a motivating example, which will accompany us as we develop the necessary components of the transformation throughout the paper.

In the introduction, we focused on adding complex number semantics to pairs of numbers. The complex numbers where the real and imaginary parts are integers are known as Gaussian integers, and are a countable subset of all complex numbers (with real number components). The operations defined on Gaussian integers are similar to complex number operations, and, as expected, division returns the closest rounded numbers on both real and imaginary components.

% The following implicit class defines the Gaussian integer operators on pairs of integer numbers:
% \vlad{should we include this or spare the reader?}
% \begin{lstlisting-nobreak}
% implicit class PairOfIntAsGaussianInteger(n1: (Int, Int)) {
%   def c = (n1.re, -n1.im) // conjugate 1+2i => 1-2i
%   def re = n1._1
%   def im = n1._2
%   def norm = n1.re * n1.re + n1.im * n1.im
%   def +(n2: (Int, Int)): (Int, Int) = (n1.re + n2.re, n1.im + n2.im)
%   def -(n2: (Int, Int)): (Int, Int) = (n1.re - n2.re, n1.im - n2.im)
%   def *(n2: (Int, Int)): (Int, Int) = (n1.re * n2.re - n1.im * n2.im, n1.re * n2.im + n1.im * n2.re)
%   def /(n2: (Int, Int)): (Int, Int) = {
%     val denom = n2 * n2.c
%     val numer = n1 * n2.c
%     assert(denom.im == 0) // by multiplying with the conjugate, we reduce the imaginary part of the denominator
%     (math.round(numer.re.toFloat / denom.re), math.round(numer.im.toFloat / denom.re))
%   }
% }
% \end{lstlisting-nobreak}

What is interesting about Gaussian integers is that we can define the division relation and the greatest common divisor (GCD) between any two numbers. Furthermore, computing the GCD is similar to the Euclidean algorithm for integers:

\begin{lstlisting-nobreak}
def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = {
  val rem = n1 % n2
  if (rem.norm == 0) n2 else gcd(n2, remainder)
}
\end{lstlisting-nobreak}

Unfortunately, as the algorithm recurses, it creates more and more pairs of integers, allocating many objects on the heap. If we were to run this algorithm without any virtual machine optimizations, each GCD operation would take around 100 microseconds.

\begin{lstlisting-nobreak}
scala> println(timed(() => gcd((55, 2) * (10, 4), (17, 13) * (10, 4))))
The operation took 109 us.
(10,4)
\end{lstlisting-nobreak}

However, if we encoded the Gaussian integers into 64-bit long integers instead of heap pairs of objects, we would improve the time by a factor of 3:

\begin{lstlisting-nobreak}
scala> println(timed(() => gcd((55, 2) * (10, 4), (17, 13) * (10, 4))))
The operation took 36 us.
(10,4)
\end{lstlisting-nobreak}

Ideally, this should be done without the programmer having to transform the algorithm by hand, only through an annotation:

\begin{lstlisting-nobreak}
ildl(IntPairComplexToLongComplex) {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = {
    val rem = n1 % n2
    if (rem.norm == 0) n2 else gcd(n2, remainder)
  }
}
\end{lstlisting-nobreak}

% It's important that's not a trivial transformation -- users will transform their input ... we'll look at this aspect again when rev
Although it looks simple, this is not a trivial transformation: first, the additional Gaussian integer operators, such as the modulo operator, have to be translated to use the 64-bit encoding. Also, as the signature of the |gcd| method changes, it forces its call sites to use the updated data representation, so the effects ripple out. Finally, there is a question of transforming geneics, including collections and arrays -- should the representation be optimized there as well? These are a few of the issues we encountered in our incremental data representation transformations, and which we further present in this paper.

\subsection{Data Representation Transformations}

% DRT - when the data has more than one representation - generally, the representation can be either more flexible or more efficient

% From the language perspective: Expose this difference vs transform in the compiler

% DRTs- two steps: decide on the representation of each value and introduce coercions

% Choosing the representation -- simple, but mind the generics!
%  -- for our case, we need to select the values

%% TODO: Find compelling example :)

% Introducing coercions -- optimality question

\subsection {Late Data Layout}

% In this context, Late data laout was chosen for
%  - selectivity
%  - optimality
%  - availability (in Scala)

% What does it do? Starting from a high-level concept, such as scala.Int, it transforms all references to low-level reprs

% How does LDL work? -- injects representation information in the types and uses them to introduce coercions

% 3 phases: Inject, Coerce, Commit.

% Inject

% Coerce

% Commit

\subsection{Incremental Late Data Layout}

% Global vs local/ad-hoc -- relationship between LDL and iLDL

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)

% Persisting the transformation decisions = persisting annotations
%  -- Usage across compilations
%  -- Tracking the transformer
%  -- interoperating between ``islands'' of modified code
%      -- using the same encoding
%      -- using different encodings

% Overriding - introduce an additional phase in LDL: bridge