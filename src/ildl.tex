\section{Ad-hoc Representation Transformation}
\label{sec:ildl}

This section presents the Ad-hoc Data Representation Transformation, which is based on the global, all-or-nothing Late Data Layout (LDL) transformation mechanism, extended with the necessary features to allow ad-hoc programmer-driven transformations.

% DRT - when the data has more than one representation - generally, the representation can be either more flexible or more efficient
Data can usually be represented in several ways, some more efficient and others more flexible. For example, integer numbers can use either the primitive (unboxed) value encoding, which is more efficient, or the object-based (boxed) encoding, which is more flexible. The boxed representation allows integers to act as the receivers of dynamically dispatched method calls, to be assigned to supertypes and to instantiate erased generics. However, the extra flexibility comes at a price: boxed integers are allocated on the heap so they need to be garbage-collected later. Also, all the operations on boxed integers incur an indirection overhead, leading to a tension between the two representations.

% From the language perspective: Expose this difference vs transform in the compiler
From a language perspective, there are two approaches to exposing the multiple representations of a type: either have a different (and incompatible) type for each representation, as Java does, or hide the difference and present a single high-level type, as ML, Haskell and Scala do. Either way, the final low-level bytecode or assembly code needs to handle the two representations separately, since they correspond to very different entities: references and values.

% DRTs- two steps: decide on the representation of each value and introduce coercions
% Choosing the representation -- simple, but mind the generics -- for our case, we need to select the values
Exposing a single high-level type in the language is more popular among programmers for its simplicity, but it puts more burden on the compiler, which has to do two additional steps: first, it needs to choose the data representation of each value and second, it needs to introduce coercions that switch between representations where necessary. For example, since only boxed integers can instantiate generics, any unboxed integer going into a generic container, such as a list, needs to be converted to the boxed representation. This work is done in the compiler pipeline, in so-called data representation transformations.

% Introducing LDL
The next section will present the Late Data Layout mechanism, a general data representation technique and the three properties that make it best suited for the Ad-hoc Data Representation Transformation: selectivity, optimality and consistency.

\subsection {Late Data Layout}

The Late Data Layout (LDL) mechanism is the underlying transformation used in Scala to unbox primitive types, to implement value class inlining and to specialize classes using the miniboxed encoding. It is a flexible and reliable mechanism, tested on many thousands of lines of code. % making it a good starting point for other data representation transformations. % This chapter will present the LDL mechanism in detail.

% In this context, Late data laout was chosen for its ability to selectivity pick values to be transformed and the optimality in introducing coercions
LDL allows selectively picking the representation for each value and automatically introduces the necessary coercions in a consistent and optimal way. Selectively choosing the representation of each value can be done either by the programmer, through annotations or by the compiler, based on predefined rules.

% What does it do? Starting from a high-level type (or concept), such as |scala.Int|, it transforms all references to low-level representations
Using LDL, a language can expose high-level types (called high-level concepts in the LDL terminology), such as the integer type exposed by Scala, |Int|, which can represent either a boxed or unboxed value in the low-level bytecode. In the following example, we have values of types |Int| and |Any|, where |Any| is the top of the Scala type system, and thus a supertype of |Int|:

\begin{lstlisting-nobreak}
val i: Int = 1
val j: Int = i
val k: Any = j
\end{lstlisting-nobreak}

Since Scala compiles down to Java bytecode, during compilation, the LDL-based primitive unboxing transformation bridges the gap between the high-level |Int| concept and its two representations: the unboxed |int| and the boxed |java.lang.Integer| representation. Along the way, it introduces the necessary coercions between these two representations. For example, the code above is translated to:

\begin{lstlisting-nobreak}
val i: `int` = 1
val j: `int` = i
val k: Any = Integer.valueOf(j)
\end{lstlisting-nobreak}

%How does LDL work? -- injects representation information in the types and uses them to introduce coercions
%3 phases: Inject, Coerce, Commit.
The LDL mechanism transforms the data representation in three phases: \inject{}, \coerce{} and \commit{}. Each of the phases is responsible for a property of the transformation: \inject{} makes LDL selective, \coerce{} makes it optimal and \commit{} makes it consistent. In our examples, we show the equivalent source code for the program abstract syntax trees (ASTs) after each of these phases.

% Inject
\subsubsection{The \inject{} phase} is responsible for marking each value with its desired representation. In the case of primitive integer unboxing, the annotation is |@unboxed|, and it signals a value should be stored in the unboxed |int| representation. As an optimization, instead of adding another |@boxed| annotation, values that are not marked are automatically considered as boxed. Following the \inject{} phase, the previous example will be transformed to:

\begin{lstlisting-nobreak}
val i: `@unboxed` Int = 1 // Int can be unboxed => add @unboxed annotation
val j: `@unboxed` Int = i // Int can be unboxed => add @unboxed annotation
val k: Any = j                  // Any cannot be unboxed => requires boxed value
\end{lstlisting-nobreak}

The \inject{} phase gives LDL the selective nature, allowing it to mark each individual value with its representation. For example, it would have been equally correct if the marking rules decided that |j| should be boxed, in which case its type would not have been marked. One of the tricks employed by the LDL transformation is that, during the \inject{} phase boxed and unboxed values are still compatible, so there is no need for coercions.

% Coerce
\subsubsection{The \coerce{} phase,} as its name suggests, introduces coercions. This is done by changing the annotation semantics: annotated types become incompatible among themselves and with their un-annotated counterparts. This change in the annotation semantics corresponds to introducing the different representations: each annotation corresponds to a representation, and representations are not compatible with each other. With this change, an assignment from one representation to another will have mismatching types. Therefore, by re-type-checking the tree, the \coerce{} phase can detect representation mismatches and can patch them using coercions. In the example, the last line contains such a mismatch:

\begin{lstlisting-nobreak}
val i: @unboxed Int = 1 // expected: @unboxed, found: @unboxed
val j: @unboxed Int = i // expected: @unboxed, found: @unboxed
val k: Any = `box`(j)             // expected:  <@boxed>, found: @unboxed => box value
\end{lstlisting-nobreak}

The \coerce{} phase brings the optimal nature of the LDL transformation. Instead of explaining how this is achieved, we will use an example to show what optimality means. Given the following two definitions:

\begin{lstlisting-nobreak}
val c: Boolean = ...
val l1: @unboxed Int = if (c) i else j
val l2: @unboxed Int = `unbox`(if (c) `box`(i) else `box`(j)
\end{lstlisting-nobreak}

It is clear that the two definitions will always produce the same result. Still, the first one is markedly better: it does not execute any coercions, compared to second definition, which executes 2 coercions regardless of the value of |c|. These subtle sub-optimalities can slow down the program the execution, increase the heap footprint and the bytecode size. This is why the \coerce{} phase needs to optimal. The LDL paper \cite{ldl} makes the following (intuition-based but not proven) claim: in any given terminating execution trace through the transformed  program, the number of coercions executed is minimal, modulo the annotations introduced by the \inject{} phase and the transformations in the \commit{} phase. What this means, for us, is that given a set of annotations, we're guaranteed the \coerce{} phase will introduce the minimum overhead.

% Commit
\subsubsection{The \commit{} phase} is responsible for introducing the actual representations. In the case of primitive unboxing, |@unboxed Int| is replaced by |int| and |Int|, which is considered boxed, is replaced by |java.lang.Integer|. The |box| and |unbox| coercions are also replaced by the creation of objects and, respectively, by the extraction of the unboxed value.

\begin{lstlisting-nobreak}
val i: `int` = 1
vla j: `int` = i
val k: Any = `Integer.valueOf`(j)
\end{lstlisting-nobreak}

The \commit{} phase is responsible for the consistency of the transformation. Since the program abstract syntax tree (AST) has been checked by the type-system extended with representation semantics, the \commit{} phase is guaranteed to correctly handle the value representations and to correctly coerce between them. This allows the \commit{} phase to be a very simple, syntax-based, transformation over the program abstract syntax tree (AST).

% Object-oriented support
\subsubsection{Object-Oriented Patterns.}

Aside from introducing coercions, data representation transformations must handle object-oriented patterns, such as method calls and subtyping. Not all representations can be used with these patterns, such as, for example, calling the |toString| method on the unboxed |int| representation:

\begin{lstlisting-nobreak}
val a: `@unboxed Int` = 1
println(a.toString)
\end{lstlisting-nobreak}

Fortunately, LDL allows the transformations to handle these cases with ease: by assigning the non-annotated type to the most flexible representation and requiring the method call receivers to have non-annotated types, LDL makes it easy to correctly handle object-oriented patterns. In the case of calling the |toString| method, the |@unboxed Int| receiver will be boxed, so it can act as the receiver of the method call. Subtyping is handled in a similar fashion, by requiring the most flexible representation:

\begin{lstlisting-nobreak}
val a: @unboxed Int = 1
println(`box`(a).toString)
\end{lstlisting-nobreak}

To improve performance, the LDL mechanism also supports extension methods. For example, if the |extension_toString| method is available for the unboxed |int| representation, there is no need to convert it to the boxed representation just to call |toString| on it. Instead, the call takes place without a representation conversion:

\begin{lstlisting-nobreak}
val a: @unboxed Int = 1
println(`extension_toString`(a))
\end{lstlisting-nobreak}

% Limited code scopes
\subsubsection{Support for Generics.}
The Late Data Layout mechanism is agnostic to generics. This means that, depending on the transformation semantics and the implementation of generics, the mechanism can inject annotations in the type arguments or not. For example, if generics are erased, a list of integers will have type |List[Int]|, since values need to be boxed. If generics are unboxed and reified, the list type will be |List[@unboxed Int]|. In the original paper \cite{ldl}, the authors show examples of both cases, where annotations are propagated inside generics and when they are not, showing how the LDL mechanism adapts seamlessly to either case.

Having seen the Late Data Layout mechanism at work for unboxing primitive types, we can now look at how it can be extended to handle ad-hoc programmer-driven data representation transformations.

\subsection{Ad-hoc Data Representation Transformation}

% DEFINE WHAT WE WANT
%  - transform scopes of code, where the scope can contain anything from an expression to a method or class definition
The goal of the ADR transformation is to relax two constraints from previous data representation transformations: first, allow the transformation to take place for limited scopes, ranging from an expression all the way to complete class or package definitions and to allow custom, programmer-defined alternative representations.

Unfortunately, relaxing these two constraints breaks core invariants of the LDL transformation. The following sections will present these invariants and explain how the ART transformation restores and preserves them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Persisting the Data Representation Information}
\label{sec:ildl:signatures}

%  - make sure that separate compilation still works (e.g: code can be called from a separately compiled source)
Relaxing the global, all-or-nothing nature of LDL and allowing it to be limited to scopes breaks one of its core invariants: the fact that, throughout separate compilations, method and field signatures transform according to the same (context-free) rules, therefore yielding consistent object layouts. This means that, knowing a method's high-level signature, based on the high-level concept (for example |Int|), we can unambiguously determine the low-level signature. For example the method:

\begin{lstlisting-nobreak}
def valueAtIndex(lst: List[Int], idx: Int) = ...
\end{lstlisting-nobreak}

Will always be compiled to the low-level bytecode signature:

\begin{lstlisting-nobreak}
def valueAtIndex(lst: List[`java.lang.Integer`], idx: `int`) = ...
\end{lstlisting-nobreak}

This makes it possible to call methods already lowered to bytecode in previous compilation sessions without the risk of their signature not matching the expected signature.

%  - correctness: make sure that we can't make any calls that are not according to the type system
However, when limiting the data representation transformation to a scope, we could, for example, only include its definition. Let us return to our example:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = ...
}
\end{lstlisting-nobreak}

In this case, the low-level signature for the |gcd| method would be:

\begin{lstlisting-nobreak}
def gcd(n1: `long`, n2: `long`): `long` = ...
\end{lstlisting-nobreak}

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)
If, in the bytecode, we stored the high-level method signature, using pairs of integers, a separate compilation would not be aware of the data representation transformation that occurred, so it might pass two pairs of integers on the stack, which would break the low-level execution. On the other hand, if the separate compilation would look at both the high-level and low-level signatures, one taken from the class file metadata and the one from the actual bytecode, it would notice a discrepancy: the pair of integer arguments from the high-level code somehow transformed into unboxed long integer arguments. But this would still be insufficient to call the method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Global vs local/ad-hoc -- relationship between LDL and iLDL + separate compilation
% Where does the transformation take place -- difference between high-level signatures and low-level signatures \ldots
How can the pairs of integers be transformed into long integers in a separate compilation, which is not aware of the ADRT transformation semantics? The separate compilation would not be aware of the |IntPairComplexToLongComplex| object, which handles the transformations. Therefore, even looking at both the high-level and low-level signatures is not enough, as the separate compilation is missing the semantic link between the two data representations.

To solve this problem, we need to first annotate the values using that will be transformed, in a phase similar to the LDL \inject{} phase:

\begin{lstlisting-nobreak}
def gcd(
    n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
    n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
  ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = ...
\end{lstlisting-nobreak}

The key to limiting the ADR transformation to a scope is \textbf{persisiting the high-level signature with the ADRT annotation} in the bytecode, along with the low-level method bytecode. This allows a future separate compilation stage to derive two critical pieces of information about the |gcd| method:

\begin{itemize}
  \item its low-level signature, based on the transformation description object, \\ |IntPairComplexToLongComplex|, which contains both the high-level type, |(Int, Int)| and its representation, |Long|;
  \item the transformation necessary when calling the |gcd| method from a non-transformed scope.
\end{itemize}

Knowing this critical piece of information, we can use the LDL transformation on the call to |gcd| made in a different separate compilation stage:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Injection -- before storing signatures, bridge, coerce and commit come later.
During the type-checking and the \inject{} phase, the high-level signature for |gcd| would be loaded from the bytecode and the call would be type-checked against the loaded signature. Remember that, before the \coerce{} phase, annotated types are compatible among themselves and with non-annotated types:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(
//      n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
//      n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
//    ): `@repr(IntPairComplexToLongComplex)` (Int, Int)
val res: (Int, Int) =
  gcd(
    (55, 2),   // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
    (17, 13)  // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
  )             // expexted: (Int, Int) found: @repr(...) (Int, Int) => okay
\end{lstlisting-nobreak}

During the \coerce{} phase, re-type-checking the tree will introduce coercions where annotated types and non-annotated types mismatch. It is important that the coercions carry the transformation description object:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  fromRepr(IntPairComplexToLongComplex, gcd(
    toRepr(IntPairComplexToLongComplex, (55, 2)),
    toRepr(IntPairComplexToLongComplex, (17, 13)
  ))
\end{lstlisting-nobreak}

Finally, during the \commit{} phase, the encoding and decoding methods from the transformation description object are used:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  IntPairComplexToLongComplex.fromRepr(gcd(
    IntPairComplexToLongComplex.toRepr((55, 2)),
    IntPairComplexToLongComplex.toRepr((17, 13))
  ))
\end{lstlisting-nobreak}

This concludes the explanation of the signature persistence problem. The following paragraphs will explain a series of corner cases and interactions of the ADR transformation.

\subsubsection{Composability}

The signature persistence solution has two advantages:
\begin{enumerate}
  \item it allows code from different scopes to compose, across separate compilation;
  \item it allows a high-level type to use different representations;
  \item it allows nested scopes;
\end{enumerate}

Let us look at the first advantage: composability: Can code from a different source file, or even from a separate build use the ADR transformation to optimize a call to method |gcd| in a separate compilation? The answer is yes:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  val n1: (Int, Int) = ...
  val n2: (Int, Int) = ...
  val res: (Int, Int) = gcd(n1, n2)
}
\end{lstlisting-nobreak}

In this example, the first step is the \inject{} phase, that will add the |@repr| annotation to the values:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(n1: @repr(...) (Int, Int), n2: @repr(...) (Int, Int)): @repr(...) (Int, Int)
val n1: `@repr(...)` (Int, Int) = ...
val n2: `@repr(...)` (Int, Int) = ...
val res: `@repr(...)` (Int, Int) = gcd(n1, n2)
\end{lstlisting-nobreak}

Now, going into the \coerce{} phase, no coercions will be introduced, as the signatures match. Therefore, the call to |gcd| will take place without any coercions for the arguments and the return type. This gives the ADR transformation an important property: \textbf{optimized scopes are composable across source files and across separate compilation runs}. This is a highly desirable property, which allows optimized code from different scopes to naturally collaborate in order to use the more optimal representation. Following the \commit{} phase, our call will be:

\begin{lstlisting-nobreak}
val n1: `Long` = ...
val n2: `Long` = ...
val res: `Long` = gcd(n1, n2)
\end{lstlisting-nobreak}

Let us now look at the second advantage: allowing a high-level type to use different representations. This can be shown in another example:

\begin{lstlisting-nobreak}
adrt(IntPairAsLong)   { var x: (Int, Int) = (3, 5) }
adrt(IntPairAsDouble) { val y: (Int, Int) = (2, 6); x = y }
\end{lstlisting-nobreak}

At a high level, the code is correct: the variable |x| is set to the value of |y|, both of them having high-level types |(Int, Int)|. However, being in different scopes, these two values will be encoded differently, |x| as a long integer and |y| as a double-precision floating point. In this situation, how would the transformation occur? The high-level type-checking will succeed, as the high-level types match. Later, during the \inject{} transformation, the |adrt| scope will be inlined:

\begin{lstlisting-nobreak}
var x: `@repr(IntPairAsLong)` (Int, Int) = (3, 5)
val y: `@repr(IntPairAsDouble)` (Int, Int) = (2, 6)
x = y
\end{lstlisting-nobreak}

The \coerce{} phase will observe the mismatching signatures in the last line:

\begin{lstlisting-nobreak}
var x: @repr(IntPairAsLong) (Int, Int) = `toRepr`(IntPairAsLong, (3, 5))
val y: @repr(IntPairAsDouble) (Int, Int) = `toRepr`(IntPairAsDouble, (2, 6))
x = `toRepr(IntPairAsLong, `fromRepr`(IntPairAsDouble, y))
\end{lstlisting-nobreak}

What happens is that, in the \coerce{} phase the value |x| is converted from a double to a pair of integers, which is subsequently converted to a long integer. This allows \textbf{composing scopes that use the same high-level type even across different representations}. The \commit{} phase will transform the example to:

\begin{lstlisting-nobreak}
var x: `Long` = IntPairAsLong.toRepr((3, 5))
val y: `Double` = IntPairAsDouble.toRepr((2, 6))
x = IntPairAsLong.toRepr(IntPairAsDouble.fromRepr(y)) // Double => Long
\end{lstlisting-nobreak}

Finally, a last composability question is whether several ADR transformations can be nested. This is indeed the case, as long as they don't target the same high-level type:

\begin{lstlisting-nobreak}
adrt(ListOfIntPairAsArrayOfLong) {
  adrt(IntPairAsLong) {
    ...
  }
}
\end{lstlisting-nobreak}

This property is another very important property, since it allows \textbf{transformation scope nesting}, which is very important in optimizing generics. The object model section (\S\ref{sec:ildl:generics}) develops this subject.

\subsubsection{Safety}

Let us now focus on a safety problem: calling based on the representation. Let us assume we have two high-level types that share the representation type, such as, for example, a pair of integers and a pair of floating-point numbers, both of which could be encoded as a long integer. Could data pass across the representation type?

\begin{lstlisting-nobreak}
adrt(IntPairAsLong) { def foo(p: (Int, Int)) = ... }
adrt(FloatPairAsLong) { foo((1f, 2f)) }
foo(123l)
\end{lstlisting-nobreak}

The answer is no: the high-level type-checking will reject both calls to the |foo| method based on the mismatching high-level types. Therefore, persisting the high-level signatures provides an important safety guarantee, namely that high-level types cannot mix even if they share the same representation type.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Handling Generics and The Object Model}
\label{sec:ildl:generics}


% 2 Aspects \ldots
\subsubsection{Generics}
%  - handle generics and the object model correctly

% Generics
%  -- Nesting datastructures
Can we transform |List[(Int, Int)]| into |List[Long]|. In the general case, no, for two reasons:
\begin{itemize}
  \item since it could break aliasing (for mutable data structures)
  \item since there is no method available to transform from one representation to the other
\end{itemize}

Solution: we could either add methods for transforming data structures in the transformation description object or, if there is no such method available, the correctness-preserving approach is not to transform the representation inside generics.


\subsubsection{The Object Model: Subtyping and Overriding}
% Overriding - introduce an additional phase in LDL: bridge
We add bridges, therefore the ILDL transformation has four phases instead of three: inject, bridge, coerce and commit.

How do you override a class with a transformed method?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preserving the Semantics}
\label{sec:ildl:semantics}

%  - for performance reasons we want to have something like LDL's extension methods

\subsubsection{Semantics of the Transformed Type}
%  -- Liskov substitution principle
reviewers may argue that data containers are generic and flexible in order to ease evolution of the data structures. Therefore transforming non-final containers might lose their semantics, since we fix the semantics of operators, which otherwise would have been dynamically dispatched to the most specific implementation. But that can be argued against using the Liskov principle -- if a subclass of the container modifies the behavior of an operator, even the original program's semantics may now be incorrect, therefore our transformation won't make correctness worse. Therefore, according to the Liskov principle, as long as the updated (static) operators are semantically equivalent to the data container's, the transformation will not affect the program semantics.

% Semantics changes
\subsubsection{Methods and Operators of the Object}
% Operators
%  -- transformation tracker
We can always decode the representation to expose the high-level type and make the call based on that. Yet, this is inefficient. The solution is to short-circuit the calls to the operators and perform them directly on the encoded value, much like extension methods work for value classes.

Short-cutting methods are located in the transformation description object, which needs to contain:
\begin{itemize}
  \item transformations between the high-level type and the representation (and back);
  \item (optional) transformations between generic containers with the high-level type (|List[(Int, Int)]|) and the generic container with the improved representation (|List[Long]|);
  \item (optional) operators and methods on the encoded representation, such as |+|, |-|, |*|, |/|, |%| and |norm|.
\end{itemize}

Operators need not required their arguments to use the high-level type: for example, when defining the |+| operator, we need to force the second operator to use the high-level type |(Int, Int)|. Instead, we accept a value of type |@encoded Long|, which allows it to accept the optimized representation for the other value as well. Interestingly, this does not prevent it from accepting the high-level type |(Int, Int)|: based on annotations, the ildl transformation knows the |(Int, Int)| value must be converted to a |Long| value.

