\section{Related Work}
\label{sec:related}


Changing data representations is a well-established and time-honored
programming need. Techniques for removing abstraction barriers appear
in the literature since the invention of high-level programming
languages and often target low-level data representations. However,
our technique is distinguished by its automatic determination of when
data representations should be transformed, while giving the
programmer control of how to perform this transformation and on which
scope it is applicable. We survey some recent related work.

As discussed earlier, the standard optimizations that are closest to
our approach are value classes~\cite{sip-value-classes} and class
specialization~\cite{iuli-thesis,miniboxing}. These are optimizations
with great practical value, and most modern languages have felt a need
for them. For instance, specialization optimizations have recently
been proposed for adoption in Java, with full VM
support~\cite{goetz-specialization}. Rose has an analogous proposal
for value
classes~\cite{rose-value-classes-vm,rose-value-classes-tearing} in
Java. Unlike our approach, all the above are whole-program data
representation transformations and receive limited programmer input
(e.g., a class annotation).

Virtual machine optimizations often also manage to produce efficient
low-level representations. Modern VMs, such as
Truffle~\cite{Wurthinger:2013:OVR:2509578.2509581} and
PyPy~\cite{PyPyTracing} attempt specialization and inference of
optimized layouts. However, the ability to perform complex inferences
dynamically is limited, and there is no way to draw domain-specific
knowledge from the programmer. Generally VM optimizations are often
successful at approaching the efficiency of a static language in a
dynamic setting, but not successful in reliably exceeding it.

In terms of transformations, we already discussed LDL~\cite{ldl} in
the Scala setting. Similar approaches, with different specifics in the
extent of type system and customization support, have been applied to
Haskell~\cite{spj-unboxed-values}. Foundational work exists for ML,
with Leroy~\cite{leroy-unboxed-objects} presenting a transformation
for unboxing objects, with the help of the type system. Later work
extends~\cite{thiemann-unboxed-objects-cps} and
generalizes~\cite{shao-flexible-representation-analysis} such
transformations.

In the specific setting of data structure specialization, the CoCo
approach~\cite{Xu:2013:CSA:2524984.2524986} adaptively replaces uses
of Java collections with optimized representations.  CoCo has a
similar high-level goal as our techniques, yet focuses explicitly on
collections only.  Approaches that only target a finite number of
classes (data structure implementations) can be realized entirely in a
library. An adaptive storage strategy for Python collections
\cite{Bolz:2013:SSC:2509136.2509531}, for instance, switches
representations once collections become polymorphic or once they
acquire many elements.



\vlad{this is the dropping ground for different related work we're aware of}



\begin{itemize}
%  \item dynamic language vms V8,
%  Truffle~\cite{Wurthinger:2013:OVR:2509578.2509581},
%  PyPy~\cite{PyPyTracing}: shape analysis, begone tagging, hidden
%  classes

  \item inlining + escape analysis + allocation sinking in virtual machines can also change the representation

%  \item ldl \cite{ldl}, haskell transformations
%  \cite{spj-unboxed-values} \cite{thiemann-unboxed-objects-cps}
%  \cite{shao-flexible-representation-analysis}, unboxed objects and
%  polymorphism \cite{leroy-unboxed-objects}

  \item til \cite{tarditi-til} \cite{harper-intensional-type-analysis}, napier88 \cite{morrison-napier88}, etc...

%  \item value classes\cite{sip-value-classes}, specialization
%  \cite{iuli-thesis} \cite{miniboxing} -- global data representation
%  transformations -- could also be implemented in the virtual machine
%  \cite{goetz-specialization}, \cite{rose-value-classes-vm}
%  \cite{rose-value-classes-tearing}

%  \item relation to partial evaluation -- in the best case they can
%  unpack objects, inline them, but can't propose an alternative
%  representation that has nothing to do with the original program
\end{itemize}

Multi-stage programming => can optimize scopes of code, but this is (1) expensive and (2) scopes do not compose -- values defined in a scope cannot be optimized across.