\section{Introduction}
\label{sec:intro}

% Objects = encapsulated data + API. Extension methods = ad-hoc additions of the API
We can think of an object as encapsulating code and data and exposing an interface. In this context, extension methods, type classes and implicit conversions are different mechanisms that allow programmers to evolve the object interface in an ad-hoc way, by adding new code. For example, in Scala, we can use an implicit conversion to add the multiplication operator to pairs of floating-point numbers, with the semantics of complex multiplication:

\begin{lstlisting-nobreak}
scala> (0f, 1f) * (0f, 1f)
res0: (Float, Float) = (-1.0, 0.0)
\end{lstlisting-nobreak}

% Interface okay, what about the object layout?
Unlike the interface, evolving the encapsulated data is impossible because the code contains hard references the object layout. For example, the methods encapsulated by the pair, such as |swap| and |toString|, rely on the existence of two generic fields, erased to |Object|. This leads to inefficiencies, as the floating-point numbers need to be boxed, producing as much as 3 heap objects for each ``complex number'': the two boxed floats and the pair container. What if, instead of the pair, we concatenated the two 32-bit floating-point numbers into a 64-bit long integer value, that would represent the ``complex number''? We could pass that by value, sidestepping the need to allocate memory and later collect it. And, surprisingly, we could also add the desired functionality, such as arithmetic operations without a problem.

% Object layout transformations in dynamic language vms => slow (due to profiling and recompilation)
Ad-hoc object layout transformations are common in dynamic language virtual machines, such as V8 and Truffle, based on run-time value profiling. Observing the type of values at run-time and making optimistic assumptions about the shape of objects, a virtual machine can change the object layout and recompile all code that relies on the old object layout. However, if the assumptions prove too optimistic, the virtual machine needs to revert to the more general (and usually less efficient) object layout, again recompiling all code that contains hard references to the optimized object layout. As expected, this comes with important overheads, both for profiling and for the recompilation, making dynamic languages several times slower than compiled, statically typed languages.

% Object layout transformations in statically typed languages => primitive unboxing, value classes and specialization
Since transforming the object layout at run-time is expensive, a natural question to ask is whether we can leverage the statically-typed nature of a compiled language to optimized the object layout? The answer is yes. Transformations such as class specialization and value class inlining transform the object layout in order to avoid the creation of heap objects. However, both of these transformations are all-or-nothing: if a class was declared to be a value class or a specialized class during its definition, it will be transformed transitively in all the code that references it, including through separate compilation. On the other hand, if a library class was not marked for transformation at its definition site, its suboptimal layout becomes burnt into the bytecode, just like our boxing pair. And there is a good reason for this: both value and specialization transformations impose restrictions on the classes, modify the class hierarchy, duplicate and adapt methods and perform many operations to make sure they maintain the object inheritance, method overriding, type parameter variance, subtyping relations and a host of other language features. In a nutshell, they are not orthogonal to the rest of the language features, so retrofitting them is impossible in their current implementations.

% Object layout transformations in statically typed languages => not ad-hoc
Therefore, although transformations in statically typed languages can optimize the object layout, they do not meet the ad-hoc criteria: they cannot be retrofitted later and have a global, all-or-nothing nature. In our case, the pair is neither specialized nor marked as a value class, so the object representation will not be optimized at all. Even worse, specialization and value class inlining are mutually exclusive, making it impossible to represent our ``complex numbers'' as a long integer value even if we had complete control over the Scala library.

% secret ingredient => the domain-specific information provided by the programmer
So, are our ``complex numbers'', efficiently reusing code from the library, hopelessly predestined to be inefficient at run-time? In this paper we explain and show how the object layout can be safely and correctly transformed in limited scopes. Interestingly, the paper does not rely on either specialization nor value class transformation, but incrementalizes and improves the Late Data Layout transformation, which underpins and generalized the static language object layout transformations. The secret ingredient of the transformation, which we call Incremental Late Data Layout, is the programmer's intimate knowledge of the small scope of the program that will be transformed, allowing a correct and complete specification of the alternative representation.

% The paper makes the following contributions over the state of the art:
%
% \begin{itemize}
% \item it explores the problem of ad-hoc object data layout transformations, which is a novelty in itself, and presents the limitations and pitfalls of this transformation when operating on an object-oriented language;
% \item it describes a solution for ad-hoc object layout transformations, capable of handling the entire Scala language;
% \item it evaluates the performance gains from this transformation in two very different scenarios, resulting in significant increases in both cases.
% \end{itemize}

% The incremental Late Data Layout transformation is implemented (and open-sourced) and we were able to test it in two different scenarios:
%
% \begin{itemize}
% \item transforming a random limited scope in the program, given user-specified input and output semantics;
% \item retrofitting miniboxing specialization on the library-defined object-oriented function encoding, the |Function| interface, making it possible for miniboxed code to efficiently call methods.
% \end{itemize}

The main insights we expect our readers to gain are:
\begin{itemize}
  \item An understanding of the additional mechanisms necessary for ad-hoc data representation transformations (\S\ref{sec:ildl}) and the pitfalls to avoid (\S\ref{sec:pitfalls});
  \item A suggestion on how the ad-hoc data representation transformation can be exposed in the API (\S\ref{sec:impl});
  \item The confidence that ad-hoc data representation transformation can be successfully applied to improve the performance of user code (\S\ref{sec:benchmarks}.
\end{itemize}

% After the main sections of the paper (\S\ref{sec:ildl}--\S\ref{sec:benchmarks}) we review the related work (\S\ref{sec:related}) and conclude (\S\ref{sec:concls}).

The following section will describe the additional mechanisms necessary for ad-hoc data representation transformations.