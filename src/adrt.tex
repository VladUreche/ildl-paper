\section{Ad hoc Data Representation Transformation}
\label{sec:ildl}

% DEFINE WHAT WE WANT
%  - transform scopes of code, where the scope can contain anything from an expression to a method or class definition
Our Ad hoc Data Representation (ADR) transformation adds two new
elements to existing data representation transformations: first, it
enables custom, programmer-defined alternative representations; and
second, it allows the transformation to take place in limited scopes,
ranging from expressions all the way to full class or package
definitions. In this way, we can support a locally correct
transformation that may be incorrect for code outside the given scope.

% In the next sections we discuss the difficulties of supporting these features and
% our mechanisms that enable such support.

%Unfortunately, relaxing these two constraints breaks core invariants
%of most data representation transformations. The following sections
%will present these invariants and explain how we adapted the Late
%Data Layout transformation to fit these relaxed constraints.

\subsection{Ad hoc Data Representation Transformation Overview}
\label{sec:ildl:user-story}

Section \ref{sec:automating} showed how the ADR transformation is triggered, using the |adrt| marker. The running example is reproduced below for quick
reference:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = {
    val remainder = n1 % n2
    if (remainder.norm == 0) n2 else gcd(n2, remainder)
  }
}
\end{lstlisting-nobreak}

The transformation description object passed to the |adrt| marker is defined by the programmer and describes the transformation itself. For example:
%% \aggelos{I think we should explicitely define our protocol. Not formally of course but description of what consists the code below, what is the object we extend from, etc. Right?}
%% \vlad{We'll do this in the implementation section}

\begin{lstlisting-nobreak}
object IntPairComplexToLongComplex extends TransformationDescription {
  type `High` = (Int, Int)
  type `Repr` = Long
  def `toRepr`(from: (Int, Int)): Long = ...
  def `fromRepr`(to: Long): (Int, Int) = ...
  ... // extension methods
}
\end{lstlisting-nobreak}

Effectively, the programmer specifies the data representation transformation: the high-level type and its representation, the coercions between them and the extension methods that allow translating operations on the high-level type directly to its representations.

% Fortunately, the object above is the \emph{only} code the programmer needs to write to enable the ADR transformation.

Once the transformation description object is defined, our technique relieves the programmer from the rest of the refactoring necessary to transform the code:

\begin{compactitem}
\item the transformation from the high-level type to its representation and the optimal introduction of coercions when interacting with outside code (\S\ref{sec:ildl:ldl});
\item the ability for separately transformed scopes to communicate via the representation type, even across separate source files and compilation runs (\S\ref{sec:ildl:compose});
\item the correct handling of the object model and of generics in the presence of the transformation (\S\ref{sec:ildl:generics})
\item the optimal handling of methods on the optimized representation (\S\ref{sec:ildl:semantics})
\end{compactitem}

%% \vlad{These seem pretty random to me. Why did you mention these two in particular?}
% \begin{compactitem}
% \item \emph{Local type inference}, in both forward and
%   backward direction, in order to determine when there should be a
%   conversion between representations. This is handled optimally by the
%   \coerce{} phase of our extension to the LDL transformation.
% % produce a minimal number of representation conversion operations.
%
% \item Handling of correctness requirements relative to overriding,
%   dynamic dispatch, and generics (\S\ref{sec:ildl:generics}), as
%   well as optimizations (\S\ref{sec:ildl:semantics}).
% \end{compactitem}

Importantly, the programmer is responsible for ensuring the correctness of the transformation description object and of the scopes under the |adrt| marker. We will further explore this after presenting the transformation (\S\ref{sec:ildl:discussion}).

% Specifically, the ADR transformation is mainly targeted at immutable containers with value semantics and without object identity, such as database rows, records, tuples and immutable collections, which do not impose many transformation restrictions. Although these objects can be involved in referential equality checks, this should be nothing more than a fast-path guarding the slow-path that checks structural equality. Contrarily, mutable value are very difficult to transform, as the link to the original object must not be servered, as it may be aliased and updated by outside code. This is why the ADR transformation can be seen to be as correct as its description object.

% \vlad{I decided to leave the discussion subsection at the end, as it only makes sense once the reader has understood what the transformation does.}












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Representation Transformation}
\label{sec:ildl:ldl}

Unlike existing data representation transformations, like value class inlining and specialization, which have a fixed semantic and occur in sequence, the ADR transformation handles many transformation scopes concurrently, each with its own different target, representation and coercions semantics. This is a challenge, as handling the interactions between these concurrent scopes, some of which may even be nested, requires a very disciplined transformation. This section will present the composition property stemming from the concurrent nature of ADR transformation scopes.

The ADR transformation relies on a very useful Late Data Layout property: selectivity. This allows values in |adrt| scopes to be annotated for transformation, without affecting the representations outside. Yet, since each |adrt| scope has its own semantics, we had to extend LDL to allow annotations parameterized on the description object. Essentially, this makes annotated types self-sufficient by encoding the entire transformation semantics in the annotation. This, in turn, allows each value to be individually transformed.

% To this end, during the \inject{} phase, the |adrt| markers are removed while the scopes have their values annotated for the LDL transformation. Following the \inject{} phase, our |adrt| scope will be transformed to:
%
% \begin{lstlisting-nobreak}
% def gcd(
%     n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
%     n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
%   ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = {
%
%     val remainder: `@repr(IntPairComplexToLongComplex)` (Int, Int) = n1 % n2
%     if (remainder.norm == 0) n2 else gcd(n2, remainder)
%   }
% \end{lstlisting-nobreak}

% The representation type is then introduced according to the LDL mechanism, using the instructions from the description object. Instead of following each step of the transformation, it is more interesting

The result is the ability of different (and even nested) |adrt| scopes to correctly pass values, a property we call composition. Let us look at two instances of composition:

\begin{itemize}
  \item a high-level type can have different representations in different scopes, but the scopes can pass values among themselves;
  \item |adrt| scopes isolate each high-level type, barring unsound value leaks through the representation type;
\end{itemize}

\subsubsection{A high-level type can have different representations in different scopes.} This goes according to the scoped nature of the ADR transformation, which allows programmers to safely use the most efficient data representation for each task. Yet, this raises the question of whether values can be safely passed across scopes that use different representations:

\begin{lstlisting-nobreak}
adrt(IntPairToLong)   { var x: (Int, Int) = (3, 5) }
adrt(IntPairToDouble) { val y: (Int, Int) = (2, 6); `x = y` }
\end{lstlisting-nobreak}

At a high level, the code is correct: the variable |x| is set to the value of |y|, both of them having high-level type |(Int, Int)|. However, being in different scopes, these two values will be encoded differently, |x| as a long integer and |y| as a double-precision floating point number. In this situation, how will the assignment |x = y| be translated? Let us look at the transformation step by step.

The scope begins by being type-checked against the high-level types in the compiler front-end. Among other things, the compiler front-end also resolves implicits and infers all missing type annotations. Then, the  \inject{} phase takes over, removing the |adrt| markers and annotating values using the paramterized |@repr| anntotation:

\begin{lstlisting-nobreak}
var x: `@repr(IntPairToLong)` (Int, Int) = (3, 5)
val y: `@repr(IntPairToDouble)` (Int, Int) = (2, 6)
`x = y`
\end{lstlisting-nobreak}

The \coerce{} phase then notices the mismatching transformation description objects in the last line: the left-hand side is on its way to be converted to a long integer (based on description object |IntPairToLong|) while the right-hand side will become a floating point expression (based on description object |IntPairToDouble|). However, both description objects have the same high-level type, the integer pair. Therefore, it is correct to use the high-level type as a middle ground:

\begin{lstlisting-nobreak}
var x: @repr(IntPairToLong) (Int, Int) = `toRepr`(IntPairToLong, (3, 5))
val y: @repr(IntPairToDouble) (Int, Int) = `toRepr`(IntPairToDouble, (2, 6))
x = `toRepr`(IntPairToLong, `fromRepr`(IntPairToDouble, y))
\end{lstlisting-nobreak}

Finally, the \commit{} phase will transform the example to:

\begin{lstlisting-nobreak}
var x: `Long` = IntPairToLong.toRepr((3, 5))
val y: `Double` = IntPairToDouble.toRepr((2, 6))
x = IntPairToLong.toRepr(IntPairToDouble.fromRepr(y)) // Double => Long
\end{lstlisting-nobreak}

Therefore, the value |x| is converted from a double to a pair of integers, which is subsequently converted to a long integer. This shows the disciplined way in which different |adrt| scopes compose, allowing values to flow across different representations, from one scope to another. Let us now look at another scenario:

% \yannis{Isn't this something we get for free from following the IDL analysis? I'm afraid I see no new idea below.} \vlad{I don't claim it as a novel insight, but it's a non-obvious result of building on top of LDL.}
\subsubsection{Different transformation scopes can be safely nested} in order to optimize multiple high-level types in the same piece of code:

\begin{lstlisting-nobreak}
adrt(FloatPairAsLong) {
  adrt(IntPairAsLong) {
    val x: (Float, Float) = (1f, 0f)
    var y: (Int, Int) = (0, 1)
    // y = x
    // y = 123l
  }
}
\end{lstlisting-nobreak}

Values of the high-level types in the inner scope are independently annotated and are transformed accordingly. A question that may occur, since both the integer and the float pairs are encoded as long integers, is whether values can leak through the representations between the high-level types, for example, by un-commenting the last two lines of the inner scope. This would open the door to incorrectly interpreting an encoded value as a different higl-level type, making the transformation unsound.

The answer is no: the code is first type-checked against the high-level types even before the \inject{} transformation has a chance to transform it. This prohibits direct transfers between the high-level types and their representations. Thus, the unsound assignments will be rejected, announcing the programmer their types do not match. This is a non-obvious benefit of using the ADR transformation instead of manually refactoring the code and using implicit conversions, which would allowed the unsound assignments to take place.

\subsubsection{However, barring programmer access to the representation type may seem limiting.} For example, a performance-consious programmer might want to transform the high-level integer pair into a floating-point pair without actually allocating heap objects. Since the programmer does not have direct access to the representation, it looks like the only solution is to decode the integer pair into a heap object, convert it to a floating-point pair and encode it back to the long integer.

This is not the only solution. As we will later see, the programmer can use extension methods to ``serialize'' the integer pair into a long integer and ``de-serialize'' it into a floating-point pair. Yet, this requires a change in the transformation description object. This is the price to pay for an automated and principled transformation.










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Extending Composition across Separate Compilation}
\label{sec:ildl:signatures}


%%% \yannis{The commented-out text below is very nice and nicely
%%% written. But it undermines our argument. If what we do is so
%%% common and general, why do we claim it as a contribution?}

%% Strongly typed languages that compile to low-level code need to store high-level semantic information about the program separately from the low-level code. This is done in order to support separate compilation, since the language usually imposes stricter rules than can be inferred from the low-level code. For example, consider the following signature in Scala:

%% \begin{lstlisting-nobreak}
%% def rewrite(c: Context)(tree: `c.Tree`, tpe: `c.Type`) = ...
%% \end{lstlisting-nobreak}

%% This signature will irreversibly lose all its path-dependent type
%% information in the low-level bytecode, as the low-level signatures
%% stored in the bytecode do not support it:

%% \begin{lstlisting-nobreak}
%% def rewrite(c: Context, tree: `Object`, tpe: `Object`) = ...
%% \end{lstlisting-nobreak}

%% Therefore, in order to allow separate compilation, Scala stores the high-level signature as bytecode metadata. This allows it to later type-check code that calls the |rewrite| method against the path-dependent signature, enforcing strong guarantees about the program behavior:

%% \begin{lstlisting-nobreak}
%% scala> rewrite(new Context())(new Object, new Object)
%% <console>:10: error: type mismatch;
%%  found   : Object
%%  required: c.Tree where val c: Context
%%               rewrite(new Context())(new Object, new Object)
%%                                             ^
%% ...
%% \end{lstlisting-nobreak}

%% This behavior is not limited to Scala: C and C++ require header files to declare the signatures of all classes and methods used, whereas Java stores generic information separately in the bytecode. Aside from the fact that high-level signatures are not derivable from the low-level ones, we have an extra problem: several low-level members can correspond to a single high-level one, making it very important to be able to consistently derive the low-level members from a high-level signature, so they can be correctly called in the low-level code.




%  - make sure that separate compilation still works (e.g: code can be called from a separately compiled source)
One of the core invariants on the LDL transformation is that, throughout separate compilations, the high-level signatures are transformed according to the same (context-free) rules, yielding consistent object layouts and low-level signatures. However, when relaxing the global, all-or-nothing nature of the LDL mechanism we are essentially breaking this invariant.
%
% For example, given method |valueAtIndex| with high-level signature:
%
% \begin{lstlisting-nobreak}
% def valueAtIndex(lst: List[Int], idx: Int) = ...
% \end{lstlisting-nobreak}
%
% The lowered signature following LDL-based primitive unboxing will always be:
%
% \begin{lstlisting-nobreak}
% def valueAtIndex(lst: List[`java.lang.Integer`], idx: `int`) = ...
% \end{lstlisting-nobreak}
%
% This allows code in the current compilation run to correctly call methods from previous separate compilations: (1) by checking the high-level signature, which may constrain the call in high-level ways (for example, though dependent types, structural types or type bounds) and (2) by consistently lowering the signature to the same bytecode-friendly low-level signature.
%
% %  - correctness: make sure that we can't make any calls that are not according to the type system
% However, when limiting the data representation transformation to a scope, we could, for example, transform a single method. Let us return to our example:
To see how this invariant is broken, we can go back to our |gcd| method:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = ...
}
\end{lstlisting-nobreak}

In this case, the lowered signature for the |gcd| method, before primitive unboxing and erasure of generics, would be:

\begin{lstlisting-nobreak}
def gcd(n1: `Long`, n2: `Long`): `Long` = ...
\end{lstlisting-nobreak}

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)
Not being aware of the ADR transformation of method |gcd|, a separate compilation could assume its bytecode would accept two pairs of integers as input. However, in the lowered bytecode, the |gcd| method accepts two long integers. A possible solution would be to add a bridge method with the expected signature, and we will later see this is necessary in some cases. However, ideally, the compiler should be able to call the transformed method directly:

% not be aware of the data representation transformation that occurred, so it might pass two pairs of integers on the stack, which would break the low-level execution. On the other hand, if the separate compilation would look at both the high-level and low-level signatures, one taken from the class file metadata and one from the actual bytecode, it would notice a discrepancy: the pair of integer arguments from the high-level code somehow transformed into unboxed long integer arguments. But this would still be insufficient to call the method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Global vs local/ad hoc -- relationship between LDL and iLDL + separate compilation
% Where does the transformation take place -- difference between high-level signatures and low-level signatures \ldots
How can the pairs of integers be transformed into long integers in a separate compilation, which is not aware of the previous ADR transformation? Even looking at both the high-level and low-level signatures side-by-side, the compiler would not be able to infer how the data arguments should be transformed, since it is missing the semantic link between the two representations: the |IntPairComplexToLongComplex| object. This is caused by relaxing the second LDL invariant: allowing custom, programmer-defined alternative representations instead of its fixed set of transformation rules.

To solve this problem, we need to run an LDL-like \inject{} phase before storing the high-level signatures. This phase annotates the high-level signature with the representation transformations that are planned for the |gcd| method. Furthermore, to inform LDL about the custom representation semantics, the annotation refers to the transformation description object:

\begin{lstlisting-nobreak}
def gcd(
    n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
    n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
  ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = ...
\end{lstlisting-nobreak}

The key to limiting the ADR transformation to a scope is \textbf{persisting the high-level signature with the injected annotation}, along with the low-level method bytecode. This allows a future separate compilation stage to derive two critical pieces of information about the |gcd| method:

\begin{itemize}
  \item its low-level signature, based on the transformation description object, \\ |IntPairComplexToLongComplex|, which contains both the high-level type, |(Int, Int)| and its representation, |Long|;
  \item the transformation necessary when calling the |gcd| method from a non-transformed scope.
\end{itemize}

Knowing these two critical pieces of information, a separate compilation can successfully call the |gcd| method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Injection -- before storing signatures, bridge, coerce and commit come later.
During the type-checking and the \inject{} phase, the high-level
signature for |gcd| is retrieved from the bytecode and the call is
type-checked against the loaded signature. Recall that, before the
\coerce{} phase, annotations are ignored for type checking, thus
differently-annotated (or non-annotated) versions of compatible types
are compatible:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(
//      n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
//      n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
//    ): `@repr(IntPairComplexToLongComplex)` (Int, Int)
val res: (Int, Int) =
  gcd(
    (55, 2),   // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
    (17, 13)  // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
  )             // expexted: (Int, Int) found: @repr(...) (Int, Int) => okay
\end{lstlisting-nobreak}

During the \coerce{} phase, re-type-checking the tree will introduce coercions whenever annotated types and non-annotated types are mixed. It is important that the coercions carry the transformation description object:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  fromRepr(`IntPairComplexToLongComplex`, gcd(
    toRepr(`IntPairComplexToLongComplex`, (55, 2)),
    toRepr(`IntPairComplexToLongComplex`, (17, 13)
  ))
\end{lstlisting-nobreak}

Finally, during the \commit{} phase, the encoding and decoding methods from the transformation description object are used:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  IntPairComplexToLongComplex.fromRepr(gcd(
    IntPairComplexToLongComplex.toRepr((55, 2)),
    IntPairComplexToLongComplex.toRepr((17, 13))
  ))
\end{lstlisting-nobreak}

%This concludes the signature persistence section. The following
%paragraphs will show the properties that stem from this decision:
%composability and safety.

We illustrate each of these cases with an example:

%% \begin{lstlisting-nobreak}
%% `adrt(IntPairComplexToLongComplex)` {
%%   val n1: (Int, Int) = ...
%%   val n2: (Int, Int) = ...
%%   val res: (Int, Int) = gcd(n1, n2)
%% }
%% \end{lstlisting-nobreak}

%% In this example, the first step is the \inject{} phase, that will add the |@repr| annotation to the values:

%% \begin{lstlisting-nobreak}
%% // loaded signature for method gcd:
%% //  def gcd(n1: @repr(...) (Int, Int), n2: @repr(...) (Int, Int)): @repr(...) (Int, Int)
%% val n1: `@repr(...)` (Int, Int) = ...
%% val n2: `@repr(...)` (Int, Int) = ...
%% val res: `@repr(...)` (Int, Int) = gcd(n1, n2)
%% \end{lstlisting-nobreak}

%% Now, going into the \coerce{} phase, no coercions will be introduced, as the signatures match. Therefore, the call to |gcd| will take place without any coercions for the arguments and the return type. This gives the ADR transformation an important property: \textbf{transformed scopes are composable across source files and across separate compilation runs}. This is a highly desirable property, which allows optimized code from different transformed scopes to seamlessly collaborate using the more optimal representation. Following the \commit{} phase, our call will be:

%% \begin{lstlisting-nobreak}
%% val n1: `Long` = ...
%% val n2: `Long` = ...
%% val res: `Long` = gcd(n1, n2) // efficient call, no coercions introduced!!!
%% \end{lstlisting-nobreak}

%Let us now look at the second advantage: allowing a high-level type
%to use different representations. This can be shown in another
%example:


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Handling Object-Oriented Patterns and Generics}
\label{sec:ildl:generics}

This section presents the interaction between object-oriented patterns and the ADR transformation. We focus on dynamic dispatch and generics, since both features require additional rules to correctly transform the program code.

\subsubsection{Dynamic dispatch}
% Part of the Object model => dynamic dispatch and overriding
is an integral part of the object-oriented programming model, allowing objects to encapsulate code. The main approach to evolving this encapsulated code is extending the class and overriding its methods. However, changing the data representation can lead to situations where source-level overriding methods are no longer overriding in the low-level translation:

\begin{lstlisting-nobreak}
class X {
  def identity(i: (Int, Int)): (Int, Int) = i
}
adrt(IntPairAsLong) {
  class Y extends X(t: (Int, Int)) {
    override def identity(i: (Int, Int)): (Int, Int) = t // instead of i
  }
}
\end{lstlisting-nobreak}

% Data representation transformations break dynamic dispatch and overriding
% The solution is introducing bridges => add a phase to the LDL transformation
In the low-level bytecode, the |identity| method in class |Y| no longer overrides method |identity| in class |X|, as its low-level signature expects a long integer instead of a pair of integers. This prompted us to extend the Late Data Layout mechanism, introducing a new \bridge{} phase, which runs just before \coerce{} and introduces method overloads, called bridges, that enable correct overriding. After the \inject{} phase, the code corresponding to class |Y| is:

\begin{lstlisting-nobreak}
class Y extends X(t: `@repr(...)` (Int, Int)) {
  override def identity(i: `@repr(...)` (Int, Int)): `@repr(...)` (Int, Int) = t
}
\end{lstlisting-nobreak}

The \bridge{} phase inserts the methods necessary to allow correct overriding:

\begin{lstlisting-nobreak}
class Y extends X(t: `@repr(...)` (Int, Int)) {
  def identity(i: `@repr(...)` (Int, Int)): `@repr(...)` (Int, Int) = t
  // overrides method identity from class X and calls the transformed method:
  @bridge override def identity(i: (Int, Int)): (Int, Int) = identity(i)
}
\end{lstlisting-nobreak}

The \coerce{} and \commit{} phases then transform class |Y| as before, resulting in a class with two methods, one with the transformed signature and another that enables overriding, marked as |@bridge|:

\begin{lstlisting-nobreak}
class Y extends X(t: `Long`) {
  def identity(i: `Long`): `Long` = t
  @bridge override def identity(i: (Int, Int)) =
    IntPairAsLong.fromRepr(identity(IntPairAsLong.toRepr(i)))
}
\end{lstlisting-nobreak}

% The backwards problem is also true => bridge + warning
If we now extend class |Y| in another |adrt| scope with the same transformation description object, overriding will take place correctly: the new class will define both the transformed method and the bridge, overriding both methods above. However, a more interesting problem occurs if we extend class |Y| from outside the |adrt| scope or from a scope with a different description object:

\begin{lstlisting-nobreak}
adrt(`IntPairAsDouble`) { // different from IntPairAsLong
  class Z(t: (Int, Int)) extends Y(t) {
    override def identity(i: (Int, Int)): (Int, Int) = i
  }
}
\end{lstlisting-nobreak}

% Following the \inject{} and \bridge{} phases, the |Z| class will be transformed to:
%
% \begin{lstlisting-nobreak}
% class Z(t: `@repr(IntPairAsDouble)` (Int, Int)) extends Y(t) {
%   def identity(i: `@repr(IntPairAsDouble)` (Int, Int)): `@repr(IntPairAsDouble)` (Int, Int) = i
%   @bridge override /* method identity in X */
%   def identity(i: (Int, Int)): (Int, Int) = identity(i)
%   @bridge override /* method identity in Y */
%   def identity(i: `@repr(IntPairAsLong)` (Int, Int)): `@repr(IntPairAsLong)` (Int, Int) = identity(i)
% }
% \end{lstlisting-nobreak}
%
% And following the \coerce{} and \commit{} phases, class |Z| becomes:

The ensuing \bridge{} phase generates two bridge methods, one for each existing signature of the method |identity|:

\begin{lstlisting-nobreak}
class Z(t: `Double`) extends Y(...) {
  def identity(i: `Double`): `Double` = i
  @bridge override def identity(i: `(Int, Int)`): `(Int, Int)` = ...
  @bridge override def identity(i: `Long`): `Long` = ...
}
\end{lstlisting-nobreak}

%This more involved transformation, with two bridges and a total of 8 representation transformations (all of which were elided in the snippet), ensures the |identity| methods in both classes |X| and |Y| are correctly overridden.

In this case, the \bridge{} phase issues a warning that up-casting class |Z| to |Y| is suboptimal, as overriding requires transforming the representation in two steps (\S\ref{sec:ildl:signatures}).

\yannis{I'm not sure I understand the above.}

\subsubsection{Generics.}
% Another question that arises: Generics - whether the ADR transformation should transform generic containers. Example:
Another problem that arises when performing ad hoc programmer-driven transformations is how to transform the data representation in generic containers. Should the ADR transformation be allowed to change the data representation stored in a |List|? We illustrate the issue with an example:

\begin{lstlisting-nobreak}
def use1(list: List[(Int, Int)]): Unit = ...
adrt(IntPairAsLong) {
  def use2(list: List[(Int, Int)]): Unit = `use1(list)`
}
\end{lstlisting-nobreak}

% In the very particular case of list, it's okay, but not in the general case
In the specific case of the Scala immutable list, it would be possible to convert the |list| parameter of |use2| from type |List[Long]| to |List[(Int, Int)]| and call the |use1| method. This can be done by mapping over the list and transforming the representation of each element. However, this domain-specific knowledge of how to transform the container only applies to the immutable list, and not to other generic classes that may be encountered in the signature.

% Furthermore, there is an entire class of mutable containers which cannot be transformed
Furthermore, there is an entire class of containers for which this approach is incorrect: mutable containers. An invariant of mutable containers is that any elements changed will be visible to all the code that holds a reference to the cointainer. But duplicating the container itself and its elements (stored with a different representation) breaks this invariant: changes to one copy of the mutable container are not visible to its other copies, violating the invariant.

% We could use the transformation representation object to add container transformation rules, but in the current implementation we did not find an elegan and general solution.
Therefore, the approach we follow in the ADR transformation is to
preserve the high-level type inside generics.\footnote{An interesting
  future direction would be to allow the transformation description
  object to also designate transformations for generic containers.}
%, but, in the current implementation, we do not allow this.
Thus, our example after the \commit{} phase will be:

\begin{lstlisting-nobreak}
def use1(list: List[(Int, Int)]): Unit = ...
def use2(list: List[(Int, Int)]): Unit = `use1(list)`
\end{lstlisting-nobreak}

Although the integer pair cannot be transformed inside the generic
container, it is possible to change the container representation
itself: we can define a separate (optimized) representation
specifically for |List[(Int, Int)]|. Further, since transformation
scopes for different high-level types can be nested, we can transform
|List[(Int, Int)]| and |(Int, Int)| simultaneously.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Optimizing Method Invocations}
\label{sec:ildl:semantics}

% Objects encapsulate data and executable code. So far, the focus has been on the data representation, but that's not all: we also care about accessing methods of the transformed object
When choosing a generic container, such as a pair or a list, programmers are usually motivated by the very flexible interface, which allows them to quickly achieve their goal by invoking the container's many convenience methods. The presentation so far focused on optimizing the data representation, but to obtain peak performance, the method invocations need to be transformed as well:

\begin{lstlisting-nobreak}
adtr(`IntPairComplexToLongComplex`) {
  val n = (0, 1)
  println(n.toString)
}
\end{lstlisting-nobreak}

% \subsubsection{Methods and Operators of the Transformed Object}

% The normal approach taken by the LDL transformation is unnecessarily conservative: it boxes the value back and calls the method:
When handling method calls, the default LDL behavior is very conservative: it encodes the transformed representation back to its high-level type, which exposes the method, and then invokes it. This produces sub-optimal code:

\begin{lstlisting-nobreak}
val n: Long = ...
println(IntPairComplexToLongComplex.`fromRepr`(n).toString)
\end{lstlisting-nobreak}

% However, it also features extension methods, which are more efficient. However, these methods have to be added manually to the transformation description object to be used by the ADR transformation:
To optimize such cases, the LDL transformation can use extension
methods,\yannis{I don't get this. Do you mean LDL already uses
  extension methods, or that it *could* in theory? I see we even
  advertise this facility of LDL in section 3. So, how is it an ADR
  novelty? Should we just say ``we inherit and extend LDL's facility
  for ...''? Also a sentence (earlier in the paper) defining extension
  methods will be welcome for the non-Scala-versed.} when they are
available. For example, assuming the |extension_toString| exists in
the transformation description object, the example can be transformed
to:

\begin{lstlisting-nobreak}
val n: Long = ...
println(IntPairComplexToLongComplex.`extension_toString`(n))
\end{lstlisting-nobreak}

This avoids the costly pair object creation that slows down execution and inflates the heap requirements. In practice, the ADR transformation will look up the |extension_toString| method, and, in case it is not present, will warn the programmer and proceed with decoding the representation type so the dynamically dispatched method can be used.

% implicitly added methods + parameters
\subsubsection{Methods added via implicit conversions,} such as the multiplication operator |*| in the original example, add another layer of complexity:

\begin{lstlisting-nobreak}
adtr(`IntPairComplexToLongComplex`) {
  val n1 = (0, 1)
  val n2 = n1 * n1
}
\end{lstlisting-nobreak}

First, they wrap the original value in a new object, which exposes the multiplication operator, and then invoke this method:

\begin{lstlisting-nobreak}
adtr(IntPairComplexToLongComple) {
  val n1: (Int, Int) = (0, 1)
  val n2: (Int, Int) = `intPairIsComplex(n1)` * n1
}
\end{lstlisting-nobreak}

Clearly, this is a costly pattern, creating at least the pair and the wrapper object. To optimize it, the ADR transformation looks for an extension method in the transformation description object that corresponds to combining the implicit method and the operator. In practice, the name of the extension method will encode the implicit conversion and the operator, but, for simplicity, let us assume its name is |extension_*|.

There are a two restrictions on the |extension_*| method: it is required to take exactly one extra parameter compared to the |*| operator, which acts as the receiver of the extension method call, and the types of its parameters must match the types of the |*| parameters. This would produce the signature:

\begin{lstlisting-nobreak}
def extension_*(recv: `@repr(...) (Int, Int)`, n2: `(Int, Int)`): `(Int, Int)`
\end{lstlisting-nobreak}

However, this is clearly inefficient: it requires decoding the second parameter and encoding the result of the computation, producing two redundant pairs of integers on the heap. To avoid this, we relax the parameter type constraint: |extension_*|'s parameter types need to match the |*| parameter types, modulo the |@repr| annotation:

\begin{lstlisting-nobreak}
def extension_*(recv: `@repr (Int, Int)`,  n2: `@repr (Int, Int)`): `@repr (Int, Int)`
\end{lstlisting-nobreak}

Replacing this method in the compiled tree, after the \commit{} phase, produces the following code:

\begin{lstlisting-nobreak}
val n1: Long = IntPairComplexToLongComplex.toRepr((0, 1))
val n2: Long = `extension_*(n1, n1)`
\end{lstlisting-nobreak}

This code is much more efficient: the complex multiplication does not require any object allocation at all! Yet, there is still a snag.

% constructors
\subsubsection{Constructors} create heap objects before they can be encoded in the representation type. Instead of allowing them to run, the ADR transformation intercepts and rewrites constructor invocations into extension methods that output the representation type directly. Using this feature on the code above, we get:

\begin{lstlisting-nobreak}
val n1: Long = IntPairComplexToLongComplex.`toRepr_ctor(0, 1)`
val n2: Long = extension_*(n1, n1)
\end{lstlisting-nobreak}

Notice that the integers are now passed as arguments to the extension |toRepr_ctor| method, by value. This completes this scope's transformation, allowing it to execute without allocating any heap object at all.



% Semantics changes
%  -- Liskov substitution principle
\subsection{Discussion}
\label{sec:ildl:discussion}
% Terminology from http://stackoverflow.com/questions/4157639/what-is-the-antonym-of-encapsulation:
The Ad hoc Data Representation Transformation is centered around exposing the encapsulated object structure. The encapsulated data is extracted and encoded in the representation type, while methods are torn apart from the object and stored as static extension methods. In this context, how can the ADR transformation be called a ``safe'' transformation?

% De-encapsulation of containers, which are essentially value types, without a significant object identity
The explanation needs to take into account the target of the ADR transformation: immutable containers with essentially value semantics and without object identity. There are entire classes of such containers, from database rows, records, tuples, immutable collections etc. Although these objects can be involved in referential equality checks, this should be nothing more than a fast-path guarding the slow-path that checks structural equality. Furthermore, many of these containers are final, not allowing inheritance outside the collections hierarchy. And in case they are not final, they are required to adhere to the Liskov Substitution Principle \cite{liskov-substitution-principle}, which dictates that their interface methods should behave identically in any subclass of the original type.

% Bad performance
On the other hand, containers are usually meant to cover a very broad spectrum of use-cases, thus requiring generic data and many utility methods for accessing and transforming it. While this speeds up development, it makes these containers impossible to use in performance-oriented applications, not only due to the significant indirection overhead but also due to the massive amounts of garbage generated, which require the Java Virtual Machine garbage collector to regularly revisit the heap objects and collect the unused ones, adding significant jitter to the application response time.

% A middle ground
The only solution for performance-oriented applications remains to write very low-level code, which is almost impossible to evolve at the same pace as the high-level container-based code. And this is only due to the very strict nature of compilers and type systems, which only accept a small fraction of the possible correct programs, specifically the fraction that the type system prove correct. Still, there is a need for a middle ground, where the compiler rules can be overridden, but in well-defined scopes and using a principled approach. % Like the unchecked casting but at a larger scale and in a more disciplined way.

% ``Safe'' relaxation of the strict semantics,
This is where the ADR transformation comes in: it separates the reusable, generic and provably correct mechanism for programmer-driven data representation transformations, with all the necessary boilerplate, from the programmer-driven policy itself, encoded in the transformation description object. Therefore, the ADR transformation adheres to an important system design principle, the separation of mechanism and policy \cite{lampson-mechanism-policy}. In order to aid the programmer in designing and implementing the transformation description object, it can gradually include more extension methods and can be unit-tested separately. Furthermore, with a single flag, the ADR transformation can be globally disabled, allowing bugs to be easily blamed either on the data representation transformation or on the code logic.

Finally, the ADR transformation relies on the Late Data Layout mechanism \cite{ldl,ldl-www}, which has been battle-tested by the Scala community in the miniboxing plugin \cite{miniboxing,miniboxing-www} and guarantees the optimal introduction of coercions and the consistency of the resulting lowered code.
