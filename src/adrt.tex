\section{Ad hoc Data Representation Transformation}
\label{sec:ildl}

% DEFINE WHAT WE WANT
%  - transform scopes of code, where the scope can contain anything from an expression to a method or class definition
Our Ad hoc Data Representation (ADR) transformation adds two new
elements to existing data representation transformations: first, it
enables custom, programmer-defined alternative representations; and
second, it allows the transformation to take place in limited scopes,
ranging from expressions all the way to full class or package
definitions. In this way, we can support a locally correct
transformation that may be incorrect for code outside the given scope.

% In the next sections we discuss the difficulties of supporting these features and
% our mechanisms that enable such support.

%Unfortunately, relaxing these two constraints breaks core invariants
%of most data representation transformations. The following sections
%will present these invariants and explain how we adapted the Late
%Data Layout transformation to fit these relaxed constraints.

\subsection{Ad hoc Data Representation Transformation Overview}
\label{sec:ildl:user-story}

Section \ref{sec:automating} showed how the ADR transformation is triggered, using the |adrt| marker. The running example is reproduced below for quick
reference:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = {
    val remainder = n1 % n2
    if (remainder.norm == 0) n2 else gcd(n2, remainder)
  }
}
\end{lstlisting-nobreak}

The transformation description object passed to the |adrt| marker is defined by the programmer and describes the transformation itself. For example:
%% \aggelos{I think we should explicitely define our protocol. Not formally of course but description of what consists the code below, what is the object we extend from, etc. Right?}
%% \vlad{We'll do this in the implementation section}

\begin{lstlisting-nobreak}
object IntPairComplexToLongComplex extends TransformationDescription {
  type `High` = (Int, Int)
  type `Repr` = Long
  def `toRepr`(from: (Int, Int)): Long = ...
  def `fromRepr`(to: Long): (Int, Int) = ...
  ... // extension methods
}
\end{lstlisting-nobreak}

Effectively, the programmer specifies the data representation transformation: the high-level type and its representation, the coercions between them and the extension methods that allow translating operations on the high-level type directly to its representations.

% Fortunately, the object above is the \emph{only} code the programmer needs to write to enable the ADR transformation.

Once the transformation description object is defined, our technique relieves the programmer from the rest of the refactoring necessary to transform the code:

\begin{compactitem}
\item the transformation from the high-level type to its representation and the optimal introduction of coercions when interacting with outside code (\S\ref{sec:ildl:ldl});
\item the ability for separately transformed scopes to communicate via the representation type, even across separate source files and compilation runs (\S\ref{sec:ildl:compose});
\item the correct handling of the object model and of generics in the presence of the transformation (\S\ref{sec:ildl:generics})
\item the optimal handling of methods on the optimized representation (\S\ref{sec:ildl:semantics})
\end{compactitem}

%% \vlad{These seem pretty random to me. Why did you mention these two in particular?}
% \begin{compactitem}
% \item \emph{Local type inference}, in both forward and
%   backward direction, in order to determine when there should be a
%   conversion between representations. This is handled optimally by the
%   \coerce{} phase of our extension to the LDL transformation.
% % produce a minimal number of representation conversion operations.
%
% \item Handling of correctness requirements relative to overriding,
%   dynamic dispatch, and generics (\S\ref{sec:ildl:generics}), as
%   well as optimizations (\S\ref{sec:ildl:semantics}).
% \end{compactitem}

Importantly, the programmer is responsible for ensuring the correctness of the transformation description object and of the scopes under the |adrt| marker. We will further explore this after presenting the transformation (\S\ref{sec:ildl:discussion}).

% Specifically, the ADR transformation is mainly targeted at immutable containers with value semantics and without object identity, such as database rows, records, tuples and immutable collections, which do not impose many transformation restrictions. Although these objects can be involved in referential equality checks, this should be nothing more than a fast-path guarding the slow-path that checks structural equality. Contrarily, mutable value are very difficult to transform, as the link to the original object must not be servered, as it may be aliased and updated by outside code. This is why the ADR transformation can be seen to be as correct as its description object.

% \vlad{I decided to leave the discussion subsection at the end, as it only makes sense once the reader has understood what the transformation does.}












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Representation Transformation}
\label{sec:ildl:ldl}

Unlike existing data representation transformations, like value class inlining and specialization, which have a fixed semantic and occur in sequence, the ADR transformation handles many transformation scopes concurrently, each with its own different target, representation and coercions semantics. This is a challenge, as handling the interactions between these concurrent scopes, some of which may even be nested, requires a very disciplined transformation. This section will present the composition property stemming from the concurrent nature of ADR transformation scopes.

The ADR transformation relies on a very useful Late Data Layout property: selectivity. This allows values in |adrt| scopes to be annotated for transformation, without affecting the representations outside. Yet, since each |adrt| scope has its own semantics, we had to extend LDL to allow annotations parameterized on the description object. Essentially, this makes annotated types self-sufficient by encoding the entire transformation semantics in the annotation. This, in turn, allows each value to be individually transformed.

The result is the ability of different (and even nested) |adrt| scopes to correctly pass values, a property we call composition. Let us look at two instances of composition:

\begin{itemize}
  \item a high-level type can have different representations in different scopes, but the scopes can pass values among themselves;
  \item |adrt| scopes isolate each high-level type, barring unsound value leaks through the representation type;
\end{itemize}

\subsubsection{A high-level type can have different representations in different scopes.} This goes according to the scoped nature of the ADR transformation, which allows programmers to safely use the most efficient data representation for each task. Yet, this raises the question of whether values can be safely passed across scopes that use different representations:

\begin{lstlisting-nobreak}
adrt(IntPairToLong)   { var x: (Int, Int) = (3, 5) }
adrt(IntPairToDouble) { val y: (Int, Int) = (2, 6); `x = y` }
\end{lstlisting-nobreak}

At a high level, the code is correct: the variable |x| is set to the value of |y|, both of them having high-level type |(Int, Int)|. However, being in different scopes, these two values will be encoded differently, |x| as a long integer and |y| as a double-precision floating point number. In this situation, how will the assignment |x = y| be translated? Let us look at the transformation step by step.

The scope begins by being type-checked against the high-level types in the compiler front-end. Among other things, the compiler front-end also resolves implicits and infers all missing type annotations. Then, the  \inject{} phase takes over, removing the |adrt| markers and annotating values using the paramterized |@repr| anntotation:

\begin{lstlisting-nobreak}
var x: `@repr(IntPairToLong)` (Int, Int) = (3, 5)
val y: `@repr(IntPairToDouble)` (Int, Int) = (2, 6)
`x = y`
\end{lstlisting-nobreak}

The \coerce{} phase then notices the mismatching transformation description objects in the last line: the left-hand side is on its way to be converted to a long integer (based on description object |IntPairToLong|) while the right-hand side will become a floating point expression (based on description object |IntPairToDouble|). However, both description objects have the same high-level type, the integer pair. Therefore, it is correct to use the high-level type as a middle ground:

\begin{lstlisting-nobreak}
var x: @repr(IntPairToLong) (Int, Int) = `toRepr`(IntPairToLong, (3, 5))
val y: @repr(IntPairToDouble) (Int, Int) = `toRepr`(IntPairToDouble, (2, 6))
x = `toRepr`(IntPairToLong, `fromRepr`(IntPairToDouble, y))
\end{lstlisting-nobreak}

Finally, the \commit{} phase will transform the example to:

\begin{lstlisting-nobreak}
var x: `Long` = IntPairToLong.toRepr((3, 5))
val y: `Double` = IntPairToDouble.toRepr((2, 6))
x = IntPairToLong.toRepr(IntPairToDouble.fromRepr(y)) // Double => Long
\end{lstlisting-nobreak}

Therefore, the value |x| is converted from a double to a pair of integers, which is subsequently converted to a long integer. This shows the disciplined way in which different |adrt| scopes compose, allowing values to flow across different representations, from one scope to another. Let us now look at another scenario:

% \yannis{Isn't this something we get for free from following the IDL analysis? I'm afraid I see no new idea below.} \vlad{I don't claim it as a novel insight, but it's a non-obvious result of building on top of LDL.}
\subsubsection{Different transformation scopes can be safely nested} in order to optimize multiple high-level types in the same piece of code:

\begin{lstlisting-nobreak}
adrt(FloatPairAsLong) {
  adrt(IntPairAsLong) {
    val x: (Float, Float) = (1f, 0f)
    var y: (Int, Int) = (0, 1)
    // y = x
    // y = 123l
  }
}
\end{lstlisting-nobreak}

Values of the high-level types in the inner scope are independently annotated and are transformed accordingly. A question that may occur, since both the integer and the float pairs are encoded as long integers, is whether values can leak through the representations between the high-level types, for example, by un-commenting the last two lines of the inner scope. This would open the door to incorrectly interpreting an encoded value as a different higl-level type, making the transformation unsound.

The answer is no: the code is first type-checked against the high-level types even before the \inject{} transformation has a chance to transform it. This prohibits direct transfers between the high-level types and their representations. Thus, the unsound assignments will be rejected, announcing the programmer their types do not match. This is a non-obvious benefit of using the ADR transformation instead of manually refactoring the code and using implicit conversions, which would allowed the unsound assignments to take place.

\subsubsection{However, barring programmer access to the representation type may seem limiting.} For example, a performance-consious programmer might want to transform the high-level integer pair into a floating-point pair without actually allocating heap objects. Since the programmer does not have direct access to the representation, it looks like the only solution is to decode the integer pair into a heap object, convert it to a floating-point pair and encode it back to the long integer.

This is not the only solution. As we will later see, the programmer can use extension methods to ``serialize'' the integer pair into a long integer and ``de-serialize'' it into a floating-point pair. Yet, this requires a change in the transformation description object. This is the price to pay for an automated and principled transformation.










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Extending Composition across Separate Compilation}
\label{sec:ildl:signatures}

Preserving the annotation in the high-level signature enables transformed scopes to seamlessly pass encoded values, even if they are compiled from different files and in different separate compilation runs. To reason about composing scopes across different compilation runs, let us assume we already compiled the |gcd| method in the motivating example:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = ...
}
\end{lstlisting-nobreak}

In this case, after the \inject{} phase, the signature for |gcd| is:

\begin{lstlisting-nobreak}
def gcd(
    n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
    n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
  ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = ...
\end{lstlisting-nobreak}

After the representation transformation, the bytecode signature for the |gcd| method is:

\begin{lstlisting-nobreak}
def gcd(n1: `long`, n2: `long`): `long` = ...
\end{lstlisting-nobreak}

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)
When compiling source code that refers to existing low-level code, such as bytecode compiled in a previous run, compilers need to load the high-level signature of each symbol. For C and C++ this is done by parsing header files while for Java and Scala, it is done by reading the source-level signature from the bytecode metadata. However, not being aware of the ADR transformation of method |gcd|, a separate compilation could assume its bytecode would accept two pairs of integers as input. Yet, in the bytecode, the |gcd| method accepts two long integers, which makes passing pairs of integers incorrect.

The most intuitive solution is to create two methods for each transformation: the transformed method itself and a bridge, which would exposes the expected signature, accepting pairs of integers, encodes them as long integers and calls the transformed version of the |gcd| method. This approach allows calling the |gcd| method from separate compilations without being aware of the transformation. However, we can do better.

\subsubsection{Persisting transformations in signatures.} Let us assume we want to call the |gcd| method from a scope transformed using the same |IntPairComplexToLongComplex| description object, but in a different compilation run:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  val n1: (Int, Int) = ...
  val n2: (Int, Int) = ...
  val res: (Int, Int) = gcd(n1, n2)
}
\end{lstlisting-nobreak}

In this case, would it make sense to call the bridge method? The values |n1| and |n2| are already encoded, they would have to be decoded before calling the bridge method, which would encode them back. This is suboptimal. Instead, what we want is to let the |adrt| scopes become part of the high-level signature, making the transformation a first-class language feature. To do so, we persist the annotation and the reference to the transformation description object in the signature. This allows calling the transformed |gcd| method directly:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(n1: @repr(...) (Int, Int), n2: @repr(...) (Int, Int)): @repr(...) (Int, Int)
val n1: `@repr(...)` (Int, Int) = ...
val n2: `@repr(...)` (Int, Int) = ...
val res: `@repr(...)` (Int, Int) = gcd(n1, n2)
\end{lstlisting-nobreak}

With these signatures, there is no need for coercions, as all the values are annotated with the same description object. This allows |adrt| scopes to seamlessly compose even across separate compilation. Following the \commit{} phase, our call will be:

\begin{lstlisting-nobreak}
val n1: `Long` = ...
val n2: `Long` = ...
val res: `Long` = gcd(n1, n2) // efficient call, no coercions introduced!!!
\end{lstlisting-nobreak}

\subsubsection{Making bridge methods redundant.} Persisting transformation information in the high-level signatures allows us to skip creating bridges for all methods. For example, calling the |gcd| method outside the |adrt| scope is still possible:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

Since the signature for method |gcd| references the transformation description object, it is possible to use the \coerce{} phase to introduce the correct coercions:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(n1: @repr(...) (Int, Int), n2: @repr(...) (Int, Int)): @repr(...) (Int, Int)
val res: (Int, Int) =
  fromRepr(...,
    gcd(                           // expected: (Int, Int) found: @repr(...) (Int, Int)
      toRepr(..., (55, 2)),   // expected: @repr(...) (Int, Int) found: (Int, Int)
      toRepr(..., (17, 13))  // expected: @repr(...) (Int, Int) found: (Int, Int)
    )
  )
\end{lstlisting-nobreak}

The next section will show where bridge methods are still necessary.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Handling Object-Oriented Patterns and Generics}
\label{sec:ildl:generics}

This section presents the interaction between object-oriented patterns and the ADR transformation. We focus on dynamic dispatch and generics, since both features require additional rules to correctly transform the program code.

\subsubsection{Dynamic dispatch}
% Part of the Object model => dynamic dispatch and overriding
is an integral part of the object-oriented programming model, allowing objects to encapsulate code. The main approach to evolving this encapsulated code is extending the class and overriding its methods. However, changing the data representation can lead to situations where source-level overriding methods are no longer overriding in the low-level translation:

\begin{lstlisting-nobreak}
class X {
  def identity(i: (Int, Int)): (Int, Int) = i
}
adrt(IntPairAsLong) {
  class Y extends X(t: (Int, Int)) {
    override def identity(i: (Int, Int)): (Int, Int) = t // instead of i
  }
}
\end{lstlisting-nobreak}

% Data representation transformations break dynamic dispatch and overriding
% The solution is introducing bridges => add a phase to the LDL transformation
In the low-level bytecode, the |identity| method in class |Y| no longer overrides method |identity| in class |X|, as its low-level signature expects a long integer instead of a pair of integers. This prompted us to extend the Late Data Layout mechanism, introducing a new \bridge{} phase, which runs just before \coerce{} and introduces method overloads, called bridges, that enable correct overriding. After the \inject{} phase, the code corresponding to class |Y| is:

\begin{lstlisting-nobreak}
class Y extends X(t: `@repr(...)` (Int, Int)) {
  override def identity(i: `@repr(...)` (Int, Int)): `@repr(...)` (Int, Int) = t
}
\end{lstlisting-nobreak}

The \bridge{} phase inserts the methods necessary to allow correct overriding:

\begin{lstlisting-nobreak}
class Y extends X(t: `@repr(...)` (Int, Int)) {
  def identity(i: `@repr(...)` (Int, Int)): `@repr(...)` (Int, Int) = t
  // overrides method identity from class X and calls the transformed method:
  @bridge override def identity(i: (Int, Int)): (Int, Int) = identity(i)
}
\end{lstlisting-nobreak}

The \coerce{} and \commit{} phases then transform class |Y| as before, resulting in a class with two methods, one with the transformed signature and another that enables overriding, marked as |@bridge|:

\begin{lstlisting-nobreak}
class Y extends X(t: `Long`) {
  def identity(i: `Long`): `Long` = t
  @bridge override def identity(i: (Int, Int)) =
    IntPairAsLong.fromRepr(identity(IntPairAsLong.toRepr(i)))
}
\end{lstlisting-nobreak}

% The backwards problem is also true => bridge + warning
If we now extend class |Y| in another |adrt| scope with the same transformation description object, overriding will take place correctly: the new class will define both the transformed method and the bridge, overriding both methods above. However, a more interesting problem occurs if we extend class |Y| from outside the |adrt| scope or from a scope with a different description object:

\begin{lstlisting-nobreak}
adrt(`IntPairAsDouble`) { // different from IntPairAsLong
  class Z(t: (Int, Int)) extends Y(t) {
    override def identity(i: (Int, Int)): (Int, Int) = i
  }
}
\end{lstlisting-nobreak}

% Following the \inject{} and \bridge{} phases, the |Z| class will be transformed to:
%
% \begin{lstlisting-nobreak}
% class Z(t: `@repr(IntPairAsDouble)` (Int, Int)) extends Y(t) {
%   def identity(i: `@repr(IntPairAsDouble)` (Int, Int)): `@repr(IntPairAsDouble)` (Int, Int) = i
%   @bridge override /* method identity in X */
%   def identity(i: (Int, Int)): (Int, Int) = identity(i)
%   @bridge override /* method identity in Y */
%   def identity(i: `@repr(IntPairAsLong)` (Int, Int)): `@repr(IntPairAsLong)` (Int, Int) = identity(i)
% }
% \end{lstlisting-nobreak}
%
% And following the \coerce{} and \commit{} phases, class |Z| becomes:

The ensuing \bridge{} phase generates two bridge methods, one for each existing signature of the method |identity|:

\begin{lstlisting-nobreak}
class Z(t: `Double`) extends Y(...) {
  def identity(i: `Double`): `Double` = i
  @bridge override def identity(i: `(Int, Int)`): `(Int, Int)` = ...
  @bridge override def identity(i: `Long`): `Long` = ...
}
\end{lstlisting-nobreak}

%This more involved transformation, with two bridges and a total of 8 representation transformations (all of which were elided in the snippet), ensures the |identity| methods in both classes |X| and |Y| are correctly overridden.

In this case, the \bridge{} phase issues a warning that up-casting class |Z| to |Y| is suboptimal, as overriding requires transforming the representation in two steps (\S\ref{sec:ildl:signatures}).

\yannis{I'm not sure I understand the above.}

\subsubsection{Generics.}
% Another question that arises: Generics - whether the ADR transformation should transform generic containers. Example:
Another problem that arises when performing ad hoc programmer-driven transformations is how to transform the data representation in generic containers. Should the ADR transformation be allowed to change the data representation stored in a |List|? We illustrate the issue with an example:

\begin{lstlisting-nobreak}
def use1(list: List[(Int, Int)]): Unit = ...
adrt(IntPairAsLong) {
  def use2(list: List[(Int, Int)]): Unit = `use1(list)`
}
\end{lstlisting-nobreak}

% In the very particular case of list, it's okay, but not in the general case
In the specific case of the Scala immutable list, it would be possible to convert the |list| parameter of |use2| from type |List[Long]| to |List[(Int, Int)]| and call the |use1| method. This can be done by mapping over the list and transforming the representation of each element. However, this domain-specific knowledge of how to transform the container only applies to the immutable list, and not to other generic classes that may be encountered in the signature.

% Furthermore, there is an entire class of mutable containers which cannot be transformed
Furthermore, there is an entire class of containers for which this approach is incorrect: mutable containers. An invariant of mutable containers is that any elements changed will be visible to all the code that holds a reference to the cointainer. But duplicating the container itself and its elements (stored with a different representation) breaks this invariant: changes to one copy of the mutable container are not visible to its other copies, violating the invariant.

% We could use the transformation representation object to add container transformation rules, but in the current implementation we did not find an elegan and general solution.
Therefore, the approach we follow in the ADR transformation is to
preserve the high-level type inside generics.\footnote{An interesting
  future direction would be to allow the transformation description
  object to also designate transformations for generic containers.}
%, but, in the current implementation, we do not allow this.
Thus, our example after the \commit{} phase will be:

\begin{lstlisting-nobreak}
def use1(list: List[(Int, Int)]): Unit = ...
def use2(list: List[(Int, Int)]): Unit = `use1(list)`
\end{lstlisting-nobreak}

Although the integer pair cannot be transformed inside the generic
container, it is possible to change the container representation
itself: we can define a separate (optimized) representation
specifically for |List[(Int, Int)]|. Further, since transformation
scopes for different high-level types can be nested, we can transform
|List[(Int, Int)]| and |(Int, Int)| simultaneously.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Optimizing Method Invocations}
\label{sec:ildl:semantics}

% Objects encapsulate data and executable code. So far, the focus has been on the data representation, but that's not all: we also care about accessing methods of the transformed object
When choosing a generic container, such as a pair or a list, programmers are usually motivated by the very flexible interface, which allows them to quickly achieve their goal by invoking the container's many convenience methods. The presentation so far focused on optimizing the data representation, but to obtain peak performance, the method invocations need to be transformed as well:

\begin{lstlisting-nobreak}
adtr(`IntPairComplexToLongComplex`) {
  val n = (0, 1)
  println(n.toString)
}
\end{lstlisting-nobreak}

% \subsubsection{Methods and Operators of the Transformed Object}

% The normal approach taken by the LDL transformation is unnecessarily conservative: it boxes the value back and calls the method:
When handling method calls, the default LDL behavior is very conservative: it encodes the transformed representation back to its high-level type, which exposes the method, and then invokes it. This produces sub-optimal code:

\begin{lstlisting-nobreak}
val n: Long = ...
println(IntPairComplexToLongComplex.`fromRepr`(n).toString)
\end{lstlisting-nobreak}

% However, it also features extension methods, which are more efficient. However, these methods have to be added manually to the transformation description object to be used by the ADR transformation:
To optimize such cases, the LDL transformation can use extension
methods,\yannis{I don't get this. Do you mean LDL already uses
  extension methods, or that it *could* in theory? I see we even
  advertise this facility of LDL in section 3. So, how is it an ADR
  novelty? Should we just say ``we inherit and extend LDL's facility
  for ...''? Also a sentence (earlier in the paper) defining extension
  methods will be welcome for the non-Scala-versed.} when they are
available. For example, assuming the |extension_toString| exists in
the transformation description object, the example can be transformed
to:

\begin{lstlisting-nobreak}
val n: Long = ...
println(IntPairComplexToLongComplex.`extension_toString`(n))
\end{lstlisting-nobreak}

This avoids the costly pair object creation that slows down execution and inflates the heap requirements. In practice, the ADR transformation will look up the |extension_toString| method, and, in case it is not present, will warn the programmer and proceed with decoding the representation type so the dynamically dispatched method can be used.

% implicitly added methods + parameters
\subsubsection{Methods added via implicit conversions,} such as the multiplication operator |*| in the original example, add another layer of complexity:

\begin{lstlisting-nobreak}
adtr(`IntPairComplexToLongComplex`) {
  val n1 = (0, 1)
  val n2 = n1 * n1
}
\end{lstlisting-nobreak}

First, they wrap the original value in a new object, which exposes the multiplication operator, and then invoke this method:

\begin{lstlisting-nobreak}
adtr(IntPairComplexToLongComple) {
  val n1: (Int, Int) = (0, 1)
  val n2: (Int, Int) = `intPairIsComplex(n1)` * n1
}
\end{lstlisting-nobreak}

Clearly, this is a costly pattern, creating at least the pair and the wrapper object. To optimize it, the ADR transformation looks for an extension method in the transformation description object that corresponds to combining the implicit method and the operator. In practice, the name of the extension method will encode the implicit conversion and the operator, but, for simplicity, let us assume its name is |extension_*|.

There are a two restrictions on the |extension_*| method: it is required to take exactly one extra parameter compared to the |*| operator, which acts as the receiver of the extension method call, and the types of its parameters must match the types of the |*| parameters. This would produce the signature:

\begin{lstlisting-nobreak}
def extension_*(recv: `@repr(...) (Int, Int)`, n2: `(Int, Int)`): `(Int, Int)`
\end{lstlisting-nobreak}

However, this is clearly inefficient: it requires decoding the second parameter and encoding the result of the computation, producing two redundant pairs of integers on the heap. To avoid this, we relax the parameter type constraint: |extension_*|'s parameter types need to match the |*| parameter types, modulo the |@repr| annotation:

\begin{lstlisting-nobreak}
def extension_*(recv: `@repr (Int, Int)`,  n2: `@repr (Int, Int)`): `@repr (Int, Int)`
\end{lstlisting-nobreak}

Replacing this method in the compiled tree, after the \commit{} phase, produces the following code:

\begin{lstlisting-nobreak}
val n1: Long = IntPairComplexToLongComplex.toRepr((0, 1))
val n2: Long = `extension_*(n1, n1)`
\end{lstlisting-nobreak}

This code is much more efficient: the complex multiplication does not require any object allocation at all! Yet, there is still a snag.

% constructors
\subsubsection{Constructors} create heap objects before they can be encoded in the representation type. Instead of allowing them to run, the ADR transformation intercepts and rewrites constructor invocations into extension methods that output the representation type directly. Using this feature on the code above, we get:

\begin{lstlisting-nobreak}
val n1: Long = IntPairComplexToLongComplex.`toRepr_ctor(0, 1)`
val n2: Long = extension_*(n1, n1)
\end{lstlisting-nobreak}

Notice that the integers are now passed as arguments to the extension |toRepr_ctor| method, by value. This completes this scope's transformation, allowing it to execute without allocating any heap object at all.



% Semantics changes
%  -- Liskov substitution principle
\subsection{Discussion}
\label{sec:ildl:discussion}
% Terminology from http://stackoverflow.com/questions/4157639/what-is-the-antonym-of-encapsulation:
The Ad hoc Data Representation Transformation is centered around exposing the encapsulated object structure. The encapsulated data is extracted and encoded in the representation type, while methods are torn apart from the object and stored as static extension methods. In this context, how can the ADR transformation be called a ``safe'' transformation?

% De-encapsulation of containers, which are essentially value types, without a significant object identity
The explanation needs to take into account the target of the ADR transformation: immutable containers with essentially value semantics and without object identity. There are entire classes of such containers, from database rows, records, tuples, immutable collections etc. Although these objects can be involved in referential equality checks, this should be nothing more than a fast-path guarding the slow-path that checks structural equality. Furthermore, many of these containers are final, not allowing inheritance outside the collections hierarchy. And in case they are not final, they are required to adhere to the Liskov Substitution Principle \cite{liskov-substitution-principle}, which dictates that their interface methods should behave identically in any subclass of the original type.

% Bad performance
On the other hand, containers are usually meant to cover a very broad spectrum of use-cases, thus requiring generic data and many utility methods for accessing and transforming it. While this speeds up development, it makes these containers impossible to use in performance-oriented applications, not only due to the significant indirection overhead but also due to the massive amounts of garbage generated, which require the Java Virtual Machine garbage collector to regularly revisit the heap objects and collect the unused ones, adding significant jitter to the application response time.

% A middle ground
The only solution for performance-oriented applications remains to write very low-level code, which is almost impossible to evolve at the same pace as the high-level container-based code. And this is only due to the very strict nature of compilers and type systems, which only accept a small fraction of the possible correct programs, specifically the fraction that the type system prove correct. Still, there is a need for a middle ground, where the compiler rules can be overridden, but in well-defined scopes and using a principled approach. % Like the unchecked casting but at a larger scale and in a more disciplined way.

% ``Safe'' relaxation of the strict semantics,
This is where the ADR transformation comes in: it separates the reusable, generic and provably correct mechanism for programmer-driven data representation transformations, with all the necessary boilerplate, from the programmer-driven policy itself, encoded in the transformation description object. Therefore, the ADR transformation adheres to an important system design principle, the separation of mechanism and policy \cite{lampson-mechanism-policy}. In order to aid the programmer in designing and implementing the transformation description object, it can gradually include more extension methods and can be unit-tested separately. Furthermore, with a single flag, the ADR transformation can be globally disabled, allowing bugs to be easily blamed either on the data representation transformation or on the code logic.

Finally, the ADR transformation relies on the Late Data Layout mechanism \cite{ldl,ldl-www}, which has been battle-tested by the Scala community in the miniboxing plugin \cite{miniboxing,miniboxing-www} and guarantees the optimal introduction of coercions and the consistency of the resulting lowered code.
