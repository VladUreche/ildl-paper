\section{Ad-hoc Data Representation Transformation}
\label{sec:ildl}

% DEFINE WHAT WE WANT
%  - transform scopes of code, where the scope can contain anything from an expression to a method or class definition
The goal of the ADR transformation is to relax two constraints from previous data representation transformations: first, allow the transformation to take place for limited scopes, ranging from an expression all the way to complete class or package definitions and to allow custom, programmer-defined alternative representations.

Unfortunately, relaxing these two constraints breaks core invariants of the LDL transformation. The following sections will present these invariants and explain how the ART transformation restores and preserves them.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Persisting the Data Representation Information}
\label{sec:ildl:signatures}

%  - make sure that separate compilation still works (e.g: code can be called from a separately compiled source)
Relaxing the global, all-or-nothing nature of LDL and allowing it to be limited to scopes breaks one of its core invariants: the fact that, throughout separate compilations, method and field signatures transform according to the same (context-free) rules, therefore yielding consistent object layouts. This means that, knowing a method's high-level signature, based on the high-level concept (for example |Int|), we can unambiguously determine the low-level signature. For example the method:

\begin{lstlisting-nobreak}
def valueAtIndex(lst: List[Int], idx: Int) = ...
\end{lstlisting-nobreak}

Will always be compiled to the low-level bytecode signature:

\begin{lstlisting-nobreak}
def valueAtIndex(lst: List[`java.lang.Integer`], idx: `int`) = ...
\end{lstlisting-nobreak}

This makes it possible to call methods already lowered to bytecode in previous compilation sessions without the risk of their signature not matching the expected signature.

%  - correctness: make sure that we can't make any calls that are not according to the type system
However, when limiting the data representation transformation to a scope, we could, for example, only include its definition. Let us return to our example:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = ...
}
\end{lstlisting-nobreak}

In this case, the low-level signature for the |gcd| method would be:

\begin{lstlisting-nobreak}
def gcd(n1: `long`, n2: `long`): `long` = ...
\end{lstlisting-nobreak}

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)
If, in the bytecode, we stored the high-level method signature, using pairs of integers, a separate compilation would not be aware of the data representation transformation that occurred, so it might pass two pairs of integers on the stack, which would break the low-level execution. On the other hand, if the separate compilation would look at both the high-level and low-level signatures, one taken from the class file metadata and the one from the actual bytecode, it would notice a discrepancy: the pair of integer arguments from the high-level code somehow transformed into unboxed long integer arguments. But this would still be insufficient to call the method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Global vs local/ad-hoc -- relationship between LDL and iLDL + separate compilation
% Where does the transformation take place -- difference between high-level signatures and low-level signatures \ldots
How can the pairs of integers be transformed into long integers in a separate compilation, which is not aware of the ADRT transformation semantics? The separate compilation would not be aware of the |IntPairComplexToLongComplex| object, which handles the transformations. Therefore, even looking at both the high-level and low-level signatures is not enough, as the separate compilation is missing the semantic link between the two data representations.

To solve this problem, we need to first annotate the values using that will be transformed, in a phase similar to the LDL \inject{} phase:

\begin{lstlisting-nobreak}
def gcd(
    n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
    n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
  ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = ...
\end{lstlisting-nobreak}

The key to limiting the ADR transformation to a scope is \textbf{persisiting the high-level signature with the ADRT annotation} in the bytecode, along with the low-level method bytecode. This allows a future separate compilation stage to derive two critical pieces of information about the |gcd| method:

\begin{itemize}
  \item its low-level signature, based on the transformation description object, \\ |IntPairComplexToLongComplex|, which contains both the high-level type, |(Int, Int)| and its representation, |Long|;
  \item the transformation necessary when calling the |gcd| method from a non-transformed scope.
\end{itemize}

Knowing this critical piece of information, we can use the LDL transformation on the call to |gcd| made in a different separate compilation stage:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Injection -- before storing signatures, bridge, coerce and commit come later.
During the type-checking and the \inject{} phase, the high-level signature for |gcd| would be loaded from the bytecode and the call would be type-checked against the loaded signature. Remember that, before the \coerce{} phase, annotated types are compatible among themselves and with non-annotated types:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(
//      n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
//      n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
//    ): `@repr(IntPairComplexToLongComplex)` (Int, Int)
val res: (Int, Int) =
  gcd(
    (55, 2),   // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
    (17, 13)  // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
  )             // expexted: (Int, Int) found: @repr(...) (Int, Int) => okay
\end{lstlisting-nobreak}

During the \coerce{} phase, re-type-checking the tree will introduce coercions where annotated types and non-annotated types mismatch. It is important that the coercions carry the transformation description object:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  fromRepr(IntPairComplexToLongComplex, gcd(
    toRepr(IntPairComplexToLongComplex, (55, 2)),
    toRepr(IntPairComplexToLongComplex, (17, 13)
  ))
\end{lstlisting-nobreak}

Finally, during the \commit{} phase, the encoding and decoding methods from the transformation description object are used:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  IntPairComplexToLongComplex.fromRepr(gcd(
    IntPairComplexToLongComplex.toRepr((55, 2)),
    IntPairComplexToLongComplex.toRepr((17, 13))
  ))
\end{lstlisting-nobreak}

This concludes the explanation of the signature persistence problem. The following paragraphs will explain a series of corner cases and interactions of the ADR transformation.

\subsubsection{Composability}

The signature persistence solution has two advantages:
\begin{enumerate}
  \item it allows code from different scopes to compose, across separate compilation;
  \item it allows a high-level type to use different representations;
  \item it allows nested scopes;
\end{enumerate}

Let us look at the first advantage: composability: Can code from a different source file, or even from a separate build use the ADR transformation to optimize a call to method |gcd| in a separate compilation? The answer is yes:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  val n1: (Int, Int) = ...
  val n2: (Int, Int) = ...
  val res: (Int, Int) = gcd(n1, n2)
}
\end{lstlisting-nobreak}

In this example, the first step is the \inject{} phase, that will add the |@repr| annotation to the values:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(n1: @repr(...) (Int, Int), n2: @repr(...) (Int, Int)): @repr(...) (Int, Int)
val n1: `@repr(...)` (Int, Int) = ...
val n2: `@repr(...)` (Int, Int) = ...
val res: `@repr(...)` (Int, Int) = gcd(n1, n2)
\end{lstlisting-nobreak}

Now, going into the \coerce{} phase, no coercions will be introduced, as the signatures match. Therefore, the call to |gcd| will take place without any coercions for the arguments and the return type. This gives the ADR transformation an important property: \textbf{optimized scopes are composable across source files and across separate compilation runs}. This is a highly desirable property, which allows optimized code from different scopes to naturally collaborate in order to use the more optimal representation. Following the \commit{} phase, our call will be:

\begin{lstlisting-nobreak}
val n1: `Long` = ...
val n2: `Long` = ...
val res: `Long` = gcd(n1, n2)
\end{lstlisting-nobreak}

Let us now look at the second advantage: allowing a high-level type to use different representations. This can be shown in another example:

\begin{lstlisting-nobreak}
adrt(IntPairAsLong)   { var x: (Int, Int) = (3, 5) }
adrt(IntPairAsDouble) { val y: (Int, Int) = (2, 6); x = y }
\end{lstlisting-nobreak}

At a high level, the code is correct: the variable |x| is set to the value of |y|, both of them having high-level types |(Int, Int)|. However, being in different scopes, these two values will be encoded differently, |x| as a long integer and |y| as a double-precision floating point. In this situation, how would the transformation occur? The high-level type-checking will succeed, as the high-level types match. Later, during the \inject{} transformation, the |adrt| scope will be inlined:

\begin{lstlisting-nobreak}
var x: `@repr(IntPairAsLong)` (Int, Int) = (3, 5)
val y: `@repr(IntPairAsDouble)` (Int, Int) = (2, 6)
x = y
\end{lstlisting-nobreak}

The \coerce{} phase will observe the mismatching signatures in the last line:

\begin{lstlisting-nobreak}
var x: @repr(IntPairAsLong) (Int, Int) = `toRepr`(IntPairAsLong, (3, 5))
val y: @repr(IntPairAsDouble) (Int, Int) = `toRepr`(IntPairAsDouble, (2, 6))
x = `toRepr(IntPairAsLong, `fromRepr`(IntPairAsDouble, y))
\end{lstlisting-nobreak}

What happens is that, in the \coerce{} phase the value |x| is converted from a double to a pair of integers, which is subsequently converted to a long integer. This allows \textbf{composing scopes that use the same high-level type even across different representations}. The \commit{} phase will transform the example to:

\begin{lstlisting-nobreak}
var x: `Long` = IntPairAsLong.toRepr((3, 5))
val y: `Double` = IntPairAsDouble.toRepr((2, 6))
x = IntPairAsLong.toRepr(IntPairAsDouble.fromRepr(y)) // Double => Long
\end{lstlisting-nobreak}

Finally, a last composability question is whether several ADR transformations can be nested. This is indeed the case, as long as they don't target the same high-level type:

\begin{lstlisting-nobreak}
adrt(ListOfIntPairAsArrayOfLong) {
  adrt(IntPairAsLong) {
    ...
  }
}
\end{lstlisting-nobreak}

This property is another very important property, since it allows \textbf{transformation scope nesting}, which is very important in optimizing generics. The object model section (\S\ref{sec:ildl:generics}) develops this subject.

\subsubsection{Safety}

Let us now focus on a safety problem: calling based on the representation. Let us assume we have two high-level types that share the representation type, such as, for example, a pair of integers and a pair of floating-point numbers, both of which could be encoded as a long integer. Could data pass across the representation type?

\begin{lstlisting-nobreak}
adrt(IntPairAsLong) { def foo(p: (Int, Int)) = ... }
adrt(FloatPairAsLong) { foo((1f, 2f)) }
foo(123l)
\end{lstlisting-nobreak}

The answer is no: the high-level type-checking will reject both calls to the |foo| method based on the mismatching high-level types. Therefore, persisting the high-level signatures provides an important safety guarantee, namely that high-level types cannot mix even if they share the same representation type.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Handling Generics and The Object Model}
\label{sec:ildl:generics}


% 2 Aspects \ldots
\subsubsection{Generics}
%  - handle generics and the object model correctly

% Generics
%  -- Nesting datastructures
Can we transform |List[(Int, Int)]| into |List[Long]|. In the general case, no, for two reasons:
\begin{itemize}
  \item since it could break aliasing (for mutable data structures)
  \item since there is no method available to transform from one representation to the other
\end{itemize}

Solution: we could either add methods for transforming data structures in the transformation description object or, if there is no such method available, the correctness-preserving approach is not to transform the representation inside generics.


\subsubsection{The Object Model: Subtyping and Overriding}
% Overriding - introduce an additional phase in LDL: bridge
We add bridges, therefore the ILDL transformation has four phases instead of three: inject, bridge, coerce and commit.

How do you override a class with a transformed method?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preserving the Semantics}
\label{sec:ildl:semantics}

%  - for performance reasons we want to have something like LDL's extension methods

\subsubsection{Semantics of the Transformed Type}
%  -- Liskov substitution principle
reviewers may argue that data containers are generic and flexible in order to ease evolution of the data structures. Therefore transforming non-final containers might lose their semantics, since we fix the semantics of operators, which otherwise would have been dynamically dispatched to the most specific implementation. But that can be argued against using the Liskov principle -- if a subclass of the container modifies the behavior of an operator, even the original program's semantics may now be incorrect, therefore our transformation won't make correctness worse. Therefore, according to the Liskov principle, as long as the updated (static) operators are semantically equivalent to the data container's, the transformation will not affect the program semantics.

% Semantics changes
\subsubsection{Methods and Operators of the Object}
% Operators
%  -- transformation tracker
We can always decode the representation to expose the high-level type and make the call based on that. Yet, this is inefficient. The solution is to short-circuit the calls to the operators and perform them directly on the encoded value, much like extension methods work for value classes.

Short-cutting methods are located in the transformation description object, which needs to contain:
\begin{itemize}
  \item transformations between the high-level type and the representation (and back);
  \item (optional) transformations between generic containers with the high-level type (|List[(Int, Int)]|) and the generic container with the improved representation (|List[Long]|);
  \item (optional) operators and methods on the encoded representation, such as |+|, |-|, |*|, |/|, |%| and |norm|.
\end{itemize}

Operators need not required their arguments to use the high-level type: for example, when defining the |+| operator, we need to force the second operator to use the high-level type |(Int, Int)|. Instead, we accept a value of type |@encoded Long|, which allows it to accept the optimized representation for the other value as well. Interestingly, this does not prevent it from accepting the high-level type |(Int, Int)|: based on annotations, the ildl transformation knows the |(Int, Int)| value must be converted to a |Long| value.

