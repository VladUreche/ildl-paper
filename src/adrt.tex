\section{Ad hoc Data Representation (ADR) Transformation}
\label{sec:ildl}

% DEFINE WHAT WE WANT
%  - transform scopes of code, where the scope can contain anything from an expression to a method or class definition
Our Ad hoc Data Representation (ADR) transformation adds two new
elements to existing data representation transformations: first, it
enables custom, programmer-defined alternative representations; and
second, it allows the transformation to take place in limited scopes,
ranging from an expression all the way to full class or package
definitions. In this way, we can support a locally correct
transformation that is not valid for other uses of the same class.

We next discuss the difficulties of supporting these features and
our mechanisms that enable such support.

%Unfortunately, relaxing these two constraints breaks core invariants
%of most data representation transformations. The following sections
%will present these invariants and explain how we adapted the Late
%Data Layout transformation to fit these relaxed constraints.

\subsection{Ad hoc Data Representation Transformation Overview}
\label{sec:ildl:user-story}

We already saw in Section~\ref{sec:automating} how the ADR
transformation is triggered on its use site, using the |adrt|
marker. The running example is reproduced below for quick
reference.

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = {
    val remainder = n1 % n2
    if (remainder.norm == 0) n2 else gcd(n2, remainder)
  }
}
\end{lstlisting-nobreak}

The |adrt| marker receives a transformation description object
as parameter. Such objects are user-defined, following a
protocol prescribed by our ADR infrastructure. The 
transformation description object for our example is:

\begin{lstlisting-nobreak}
object IntPairComplexToLongComplex extends TransformationDescription {
  type High = (Int, Int)
  type Repr = Long
  private def pack(re: Int, im: Int) = (re.toLong << 32l) | (im.toLong & 0xFFFFFFFFl)
  def toRepr(pair: (Int, Int)) = pack(pair._1, pair._2)
  def fromRepr(l: Long @repr): (Int, Int) = (extension__1(l), extension__2(l))
  def extension__1(l: @repr Long): Int = (l >>> 32).toInt        // the ._1 method
  def extension__2(l: @repr Long): Int = (l & 0xFFFFFFFF).toInt  // ._2 method
  def extension_norm(l: @repr Long) = extension__1(l)^2 + extension__1(l)^2
  ... // other methods
}
\end{lstlisting-nobreak}

Effectively, our ADR machinery offers a domain-specific language for
transformation descriptions. The high-level type and the
representation type are specified, and so are conversion functions from
and to the different types. Any supported operations on a pair object
are translated to corresponding operations on long numbers.

The above is the \emph{only} code the programmer needs to write to
enable the ADR transformation. The compiler relieves the programmer
from the obligation to write other code that is necessary for
correctness and performance. The facilities offered for free include:

\begin{compactitem}
\item \emph{Local type inference}, in both forward and
  backward direction, in order to determine when there should be a
  conversion between representations. This is handled optimally by the
  \coerce{} phase of our extension to the LDL transformation.
% produce a minimal number of representation conversion operations.

\item Handling of correctness requirements relative to overriding,
  dynamic dispatch, and generics (\S\ref{sec:ildl:generics}), as
  well as optimizations (\S\ref{sec:ildl:semantics}).
\end{compactitem}

Importantly, the programmer is responsible for ensuring the
correctness of the transformation description object and of uses of
the |adrt| marker. Specifically, the correctness of a representation
transformation is violated for objects that do not have value
semantics in the scope where representation conversion may occur. Such
objects can get aliased and modified while in two different
representations.  In this way, changes in the object state while in
one representation will not be reflected in the other. Objects can
also be compared with reference equality, in which case the two
different representations of the same object will be found to be
distinct.

Thus, the target of the ADR transformation is (locally) immutable
containers with value semantics and without object identity. There are
large classes of such containers, from database rows, records, tuples,
immutable collections, etc. Although these objects can be involved in
referential equality checks, this should be nothing more than a
fast-path guarding the slow-path that checks structural equality.

Note that these semantic assumptions may only hold locally.  The ADR
transformation is the only facility we are aware of that can achieve
optimization in these cases, while offering the programmer (partial)
correctness and optimality guarantees.

%% \yannis{This is important but too defensive. I don't know where to
%% put it. Not here, for sure.}
% Furthermore, with a single flag, the ADR transformation can be
% globally disabled, allowing bugs to be easily blamed either on the
% data representation transformation or on the code logic.





%% \yannis{I'm not sure the para below says anything more. The
%% programmer is responsible for writing correct methods for the
%% alternate representation. But that's a given. Correct methods
%% should be compatible with overridden versions in a subclass
%% (Liskov). So, I'm not sure we even need to mention it.}

% Furthermore, many of these containers are final, not
%allowing inheritance outside the collections hierarchy. And in case
%they are not final, they are required to adhere to the Liskov
%Substitution Principle \cite{liskov-substitution-principle}, which
%dictates that their interface methods should behave identically in any
%subclass of the original type.




%%% \yannis{The text below looks like another introduction or
%%% conclusions. It doesn't belong in a section in the middle of the
%%% technical discussion, I think. I took important elements from it,
%%% though. We can have it later as a ``Discussion'' section.}

%% % Semantics changes
%% %  -- Liskov substitution principle
%% \subsection{Extension Methods and Object Semantics}
%% \label{sec:ildl:discussion}
%% % Terminology from http://stackoverflow.com/questions/4157639/what-is-the-antonym-of-encapsulation:
%% The Ad hoc Data Representation Transformation is centered around exposing the encapsulated object structure. The encapsulated data is extracted and encoded in the representation type, while methods are torn apart from the object and stored as static extension methods. In this context, how can the ADR transformation be called a ``safe'' transformation?

%% % De-encapsulation of containers, which are essentially value types, without a significant object identity
%% The explanation needs to take into account the target of the ADR transformation: immutable containers with essentially value semantics and without object identity. There are entire classes of such containers, from database rows, records, tuples, immutable collections etc. Although these objects can be involved in referential equality checks, this should be nothing more than a fast-path guarding the slow-path that checks structural equality. Furthermore, many of these containers are final, not allowing inheritance outside the collections hierarchy. And in case they are not final, they are required to adhere to the Liskov Substitution Principle \cite{liskov-substitution-principle}, which dictates that their interface methods should behave identically in any subclass of the original type.

%% % Bad performance
%% On the other hand, containers are usually meant to cover a very broad spectrum of use-cases, thus requiring generic data and many utility methods for accessing and transforming it. While this speeds up development, it makes these containers impossible to use in performance-oriented applications, not only due to the significant indirection overhead but also due to the massive amounts of garbage generated, which require the Java Virtual Machine garbage collector to regularly revisit the heap objects and collect the unused ones, adding significant jitter to the application response time.

%% % A middle ground
%% The only solution for performance-oriented applications remains to write very low-level code, which is almost impossible to evolve at the same pace as the high-level container-based code. And this is only due to the very strict nature of compilers and type systems, which only accept a small fraction of the possible correct programs, specifically the fraction that the type system prove correct. Still, there is a need for a middle ground, where the compiler rules can be overridden, but in well-defined scopes and using a principled approach. % Like the unchecked casting but at a larger scale and in a more disciplined way.

%% % ``Safe'' relaxation of the strict semantics,
%% This is where the ADR transformation comes in: it separates the reusable, generic and provably correct mechanism for programmer-driven data representation transformations, with all the necessary boilerplate, from the programmer-driven policy itself, encoded in the transformation description object. Therefore, the ADR transformation adheres to an important system design principle, the separation of mechanism and policy \cite{lampson-mechanism-policy}. In order to aid the programmer in designing and implementing the transformation description object, it can gradually include more extension methods and can be unit-tested separately. Furthermore, with a single flag, the ADR transformation can be globally disabled, allowing bugs to be easily blamed either on the data representation transformation or on the code logic.

%% Finally, the ADR transformation relies on the Late Data Layout mechanism \cite{ldl,ldl-www}, which has been battle-tested by the Scala community in the miniboxing plugin \cite{miniboxing,miniboxing-www} and guarantees the optimal introduction of coercions and the consistency of the resulting lowered code.







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Persisting the Data Representation Information}
\label{sec:ildl:signatures}


%%% \yannis{The commented-out text below is very nice and nicely
%%% written. But it undermines our argument. If what we do is so
%%% common and general, why do we claim it as a contribution?}

%% Strongly typed languages that compile to low-level code need to store high-level semantic information about the program separately from the low-level code. This is done in order to support separate compilation, since the language usually imposes stricter rules than can be inferred from the low-level code. For example, consider the following signature in Scala:

%% \begin{lstlisting-nobreak}
%% def rewrite(c: Context)(tree: `c.Tree`, tpe: `c.Type`) = ...
%% \end{lstlisting-nobreak}

%% This signature will irreversibly lose all its path-dependent type
%% information in the low-level bytecode, as the low-level signatures
%% stored in the bytecode do not support it:

%% \begin{lstlisting-nobreak}
%% def rewrite(c: Context, tree: `Object`, tpe: `Object`) = ...
%% \end{lstlisting-nobreak}

%% Therefore, in order to allow separate compilation, Scala stores the high-level signature as bytecode metadata. This allows it to later type-check code that calls the |rewrite| method against the path-dependent signature, enforcing strong guarantees about the program behavior:

%% \begin{lstlisting-nobreak}
%% scala> rewrite(new Context())(new Object, new Object)
%% <console>:10: error: type mismatch;
%%  found   : Object
%%  required: c.Tree where val c: Context
%%               rewrite(new Context())(new Object, new Object)
%%                                             ^
%% ...
%% \end{lstlisting-nobreak}

%% This behavior is not limited to Scala: C and C++ require header files to declare the signatures of all classes and methods used, whereas Java stores generic information separately in the bytecode. Aside from the fact that high-level signatures are not derivable from the low-level ones, we have an extra problem: several low-level members can correspond to a single high-level one, making it very important to be able to consistently derive the low-level members from a high-level signature, so they can be correctly called in the low-level code.




%  - make sure that separate compilation still works (e.g: code can be called from a separately compiled source)
One of the core invariants on the LDL transformation is that, throughout separate compilations, the high-level signatures are transformed according to the same (context-free) rules, yielding consistent object layouts and low-level signatures. However, when relaxing the global, all-or-nothing nature of the LDL mechanism we are essentially breaking this invariant.
%
% For example, given method |valueAtIndex| with high-level signature:
%
% \begin{lstlisting-nobreak}
% def valueAtIndex(lst: List[Int], idx: Int) = ...
% \end{lstlisting-nobreak}
%
% The lowered signature following LDL-based primitive unboxing will always be:
%
% \begin{lstlisting-nobreak}
% def valueAtIndex(lst: List[`java.lang.Integer`], idx: `int`) = ...
% \end{lstlisting-nobreak}
%
% This allows code in the current compilation run to correctly call methods from previous separate compilations: (1) by checking the high-level signature, which may constrain the call in high-level ways (for example, though dependent types, structural types or type bounds) and (2) by consistently lowering the signature to the same bytecode-friendly low-level signature.
%
% %  - correctness: make sure that we can't make any calls that are not according to the type system
% However, when limiting the data representation transformation to a scope, we could, for example, transform a single method. Let us return to our example:
To see how this invariant is broken, we can go back to our |gcd| method:

\begin{lstlisting-nobreak}
`adrt(IntPairComplexToLongComplex)` {
  def gcd(n1: (Int, Int), n2: (Int, Int)): (Int, Int) = ...
}
\end{lstlisting-nobreak}

In this case, the lowered signature for the |gcd| method, before primitive unboxing and erasure of generics, would be:

\begin{lstlisting-nobreak}
def gcd(n1: `Long`, n2: `Long`): `Long` = ...
\end{lstlisting-nobreak}

% An important question in DRTs: how to modify signatures
%  -- keeping track of transformed methods (do I have a transformed version?)
Not being aware of the ADR transformation of method |gcd|, a separate compilation could assume its bytecode would accept two pairs of integers as input. However, in the lowered bytecode, the |gcd| method accepts two long integers. A possible solution would be to add a bridge method with the expected signature, and we will later see this is necessary in some cases. However, ideally, the compiler should be able to call the transformed method directly:

% not be aware of the data representation transformation that occurred, so it might pass two pairs of integers on the stack, which would break the low-level execution. On the other hand, if the separate compilation would look at both the high-level and low-level signatures, one taken from the class file metadata and one from the actual bytecode, it would notice a discrepancy: the pair of integer arguments from the high-level code somehow transformed into unboxed long integer arguments. But this would still be insufficient to call the method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Global vs local/ad hoc -- relationship between LDL and iLDL + separate compilation
% Where does the transformation take place -- difference between high-level signatures and low-level signatures \ldots
How can the pairs of integers be transformed into long integers in a separate compilation, which is not aware of the previous ADR transformation? Even looking at both the high-level and low-level signatures side-by-side, the compiler would not be able to infer how the data arguments should be transformed, since it is missing the semantic link between the two representations: the |IntPairComplexToLongComplex| object. This is caused by relaxing the second LDL invariant: allowing custom, programmer-defined alternative representations instead of its fixed set of transformation rules.

To solve this problem, we need to run an LDL-like \inject{} phase before storing the high-level signatures. This phase annotates the high-level signature with the representation transformations that are planned for the |gcd| method. Furthermore, to inform LDL about the custom representation semantics, the annotation refers to the transformation description object:

\begin{lstlisting-nobreak}
def gcd(
    n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
    n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
  ): `@repr(IntPairComplexToLongComplex)` (Int, Int) = ...
\end{lstlisting-nobreak}

The key to limiting the ADR transformation to a scope is \textbf{persisting the high-level signature with the injected annotation}, along with the low-level method bytecode. This allows a future separate compilation stage to derive two critical pieces of information about the |gcd| method:

\begin{itemize}
  \item its low-level signature, based on the transformation description object, \\ |IntPairComplexToLongComplex|, which contains both the high-level type, |(Int, Int)| and its representation, |Long|;
  \item the transformation necessary when calling the |gcd| method from a non-transformed scope.
\end{itemize}

Knowing these two critical pieces of information, a separate compilation can successfully call the |gcd| method:

\begin{lstlisting-nobreak}
val res: (Int, Int) = gcd((55, 2), (17, 13))
\end{lstlisting-nobreak}

% Injection -- before storing signatures, bridge, coerce and commit come later.
During the type-checking and the \inject{} phase, the high-level
signature for |gcd| is retrieved from the bytecode and the call is
type-checked against the loaded signature. Recall that, before the
\coerce{} phase, annotations are ignored for type checking, thus
differently-annotated (or non-annotated) versions of compatible types
are compatible:

\begin{lstlisting-nobreak}
// loaded signature for method gcd:
//  def gcd(
//      n1: `@repr(IntPairComplexToLongComplex)` (Int, Int),
//      n2: `@repr(IntPairComplexToLongComplex)` (Int, Int)
//    ): `@repr(IntPairComplexToLongComplex)` (Int, Int)
val res: (Int, Int) =
  gcd(
    (55, 2),   // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
    (17, 13)  // expected: @repr(...) (Int, Int) found: (Int, Int) => okay
  )             // expexted: (Int, Int) found: @repr(...) (Int, Int) => okay
\end{lstlisting-nobreak}

During the \coerce{} phase, re-type-checking the tree will introduce coercions whenever annotated types and non-annotated types are mixed. It is important that the coercions carry the transformation description object:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  fromRepr(`IntPairComplexToLongComplex`, gcd(
    toRepr(`IntPairComplexToLongComplex`, (55, 2)),
    toRepr(`IntPairComplexToLongComplex`, (17, 13)
  ))
\end{lstlisting-nobreak}

Finally, during the \commit{} phase, the encoding and decoding methods from the transformation description object are used:

\begin{lstlisting-nobreak}
val res: (Int, Int) =
  IntPairComplexToLongComplex.fromRepr(gcd(
    IntPairComplexToLongComplex.toRepr((55, 2)),
    IntPairComplexToLongComplex.toRepr((17, 13))
  ))
\end{lstlisting-nobreak}

%This concludes the signature persistence section. The following
%paragraphs will show the properties that stem from this decision:
%composability and safety.

\subsubsection{Composability. } 
Persisting transformation information in signatures allows full composability
of the transformation:
%Persisting transformation information in signatures brings three advantages:
\begin{enumerate}
  \item a single high-level type can use multiple representations;
  \item code from different scopes can compose across separate compilations;
  \item ADR transformations that do not target the same high-level type can be safely nested, regardless of their representation types.
\end{enumerate}

We illustrate the first of these advantages with an example:

%% The first advantage is that code from a different source file or even from a separate compilation can use the ADR transformation to optimize a call to method |gcd| in a separate compilation:

%% \begin{lstlisting-nobreak}
%% `adrt(IntPairComplexToLongComplex)` {
%%   val n1: (Int, Int) = ...
%%   val n2: (Int, Int) = ...
%%   val res: (Int, Int) = gcd(n1, n2)
%% }
%% \end{lstlisting-nobreak}

%% In this example, the first step is the \inject{} phase, that will add the |@repr| annotation to the values:

%% \begin{lstlisting-nobreak}
%% // loaded signature for method gcd:
%% //  def gcd(n1: @repr(...) (Int, Int), n2: @repr(...) (Int, Int)): @repr(...) (Int, Int)
%% val n1: `@repr(...)` (Int, Int) = ...
%% val n2: `@repr(...)` (Int, Int) = ...
%% val res: `@repr(...)` (Int, Int) = gcd(n1, n2)
%% \end{lstlisting-nobreak}

%% Now, going into the \coerce{} phase, no coercions will be introduced, as the signatures match. Therefore, the call to |gcd| will take place without any coercions for the arguments and the return type. This gives the ADR transformation an important property: \textbf{transformed scopes are composable across source files and across separate compilation runs}. This is a highly desirable property, which allows optimized code from different transformed scopes to seamlessly collaborate using the more optimal representation. Following the \commit{} phase, our call will be:

%% \begin{lstlisting-nobreak}
%% val n1: `Long` = ...
%% val n2: `Long` = ...
%% val res: `Long` = gcd(n1, n2) // efficient call, no coercions introduced!!!
%% \end{lstlisting-nobreak}

%Let us now look at the second advantage: allowing a high-level type
%to use different representations. This can be shown in another
%example:

\begin{lstlisting-nobreak}
adrt(IntPairAsLong)   { var x: (Int, Int) = (3, 5) }
adrt(IntPairAsDouble) { val y: (Int, Int) = (2, 6); x = y }
\end{lstlisting-nobreak}

At a high level, the code is correct: the variable |x| is set to the value of |y|, both of them having high-level type |(Int, Int)|. However, being in different scopes, these two values will be encoded differently, |x| as a long integer and |y| as a double-precision floating point number. In this situation, how will the assignment |x = y| be translated? The high-level types match, but the representation types do not. The first step is to inline the two |adrt| scopes and \inject{} annotations:

\begin{lstlisting-nobreak}
var x: `@repr(IntPairAsLong)` (Int, Int) = (3, 5)
val y: `@repr(IntPairAsDouble)` (Int, Int) = (2, 6)
x = y
\end{lstlisting-nobreak}

The \coerce{} phase will observe the mismatching signatures in the last line:

\begin{lstlisting-nobreak}
var x: @repr(IntPairAsLong) (Int, Int) = `toRepr`(IntPairAsLong, (3, 5))
val y: @repr(IntPairAsDouble) (Int, Int) = `toRepr`(IntPairAsDouble, (2, 6))
x = `toRepr`(IntPairAsLong, `fromRepr`(IntPairAsDouble, y))
\end{lstlisting-nobreak}

What happens is that, in the \coerce{} phase, the value |x| is converted from a double to a pair of integers, which is subsequently converted to a long integer. This allows \textbf{composing scopes that use the same high-level type even across different representations}. Finally, the \commit{} phase will transform the example to:

\begin{lstlisting-nobreak}
var x: `Long` = IntPairAsLong.toRepr((3, 5))
val y: `Double` = IntPairAsDouble.toRepr((2, 6))
x = IntPairAsLong.toRepr(IntPairAsDouble.fromRepr(y)) // Double => Long
\end{lstlisting-nobreak}

%% Finally, a last composability question is whether several ADR transformations can be nested. This is indeed the case, as long as they don't target the same high-level type:

%% \begin{lstlisting-nobreak}
%% adrt(FloatPairAsLong) {
%%   adrt(IntPairAsLong) {
%%     ...
%%   }
%% }
%% \end{lstlisting-nobreak}

%% This is another very important property, since it allows \textbf{transformation scope nesting} in a safe way, without running the risk of interactions between high-level types or their representations.


%% \yannis{Isn't this something we get for free from following the IDL analysis? I'm afraid I see no new idea below.}
%% \subsubsection{Safety.} Let us now focus on a safety problem: assuming two high-level types that share the representation type, could data flow across the representation type from one high-level type to another? Of course, this would be incorrect, as it would interpret the data using an incorrect semantic:

%% \begin{lstlisting-nobreak}
%% adrt(IntPairAsLong) { def foo(p: (Int, Int)) = ... }
%% adrt(FloatPairAsLong) { foo((1f, 2f)) }
%% foo(123l)
%% \end{lstlisting-nobreak}

%% The answer is no: the high-level type-checking will reject both calls to the |foo| method based on the mismatching high-level types: the first call passes a floating-point pair while the second one passes a long integer. Yet, the high-level signature of method |foo| expects a pair of integers. Thus persisting the high-level signatures provides an important safety guarantee, namely that data cannot flow from one high-level type to another by way of the representation type.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Handling Object-Oriented Patterns and Generics}
\label{sec:ildl:generics}

This section presents the interaction between object-oriented patterns and the ADR transformation. We focus on dynamic dispatch and generics, since both features require additional rules to correctly transform the program code.

\subsubsection{Dynamic dispatch}
% Part of the Object model => dynamic dispatch and overriding
is an integral part of the object-oriented programming model, allowing objects to encapsulate code. The main approach to evolving this encapsulated code is extending the class and overriding its methods. However, changing the data representation can lead to situations where source-level overriding methods are no longer overriding in the low-level translation:

\begin{lstlisting-nobreak}
class X {
  def identity(i: (Int, Int)): (Int, Int) = i
}
adrt(IntPairAsLong) {
  class Y extends X(t: (Int, Int)) {
    override def identity(i: (Int, Int)): (Int, Int) = t // instead of i
  }
}
\end{lstlisting-nobreak}

% Data representation transformations break dynamic dispatch and overriding
% The solution is introducing bridges => add a phase to the LDL transformation
In the low-level bytecode, the |identity| method in class |Y| no longer overrides method |identity| in class |X|, as its low-level signature expects a long integer instead of a pair of integers. This prompted us to extend the Late Data Layout mechanism, introducing a new \bridge{} phase, which runs just before \coerce{} and introduces method overloads, called bridges, that enable correct overriding. After the \inject{} phase, the code corresponding to class |Y| is:

\begin{lstlisting-nobreak}
class Y extends X(t: `@repr(...)` (Int, Int)) {
  override def identity(i: `@repr(...)` (Int, Int)): `@repr(...)` (Int, Int) = t
}
\end{lstlisting-nobreak}

The \bridge{} phase inserts the methods necessary to allow correct overriding:

\begin{lstlisting-nobreak}
class Y extends X(t: `@repr(...)` (Int, Int)) {
  def identity(i: `@repr(...)` (Int, Int)): `@repr(...)` (Int, Int) = t
  // overrides method identity from class X and calls the transformed method:
  @bridge override def identity(i: (Int, Int)): (Int, Int) = identity(i)
}
\end{lstlisting-nobreak}

The \coerce{} and \commit{} phases then transform class |Y| as before, resulting in a class with two methods, one with the transformed signature and another that enables overriding, marked as |@bridge|:

\begin{lstlisting-nobreak}
class Y extends X(t: `Long`) {
  def identity(i: `Long`): `Long` = t
  @bridge override def identity(i: (Int, Int)) =
    IntPairAsLong.fromRepr(identity(IntPairAsLong.toRepr(i)))
}
\end{lstlisting-nobreak}

% The backwards problem is also true => bridge + warning
If we now extend class |Y| in another |adrt| scope with the same transformation description object, overriding will take place correctly: the new class will define both the transformed method and the bridge, overriding both methods above. However, a more interesting problem occurs if we extend class |Y| from outside the |adrt| scope or from a scope with a different description object:

\begin{lstlisting-nobreak}
adrt(`IntPairAsDouble`) { // different from IntPairAsLong
  class Z(t: (Int, Int)) extends Y(t) {
    override def identity(i: (Int, Int)): (Int, Int) = i
  }
}
\end{lstlisting-nobreak}

% Following the \inject{} and \bridge{} phases, the |Z| class will be transformed to:
%
% \begin{lstlisting-nobreak}
% class Z(t: `@repr(IntPairAsDouble)` (Int, Int)) extends Y(t) {
%   def identity(i: `@repr(IntPairAsDouble)` (Int, Int)): `@repr(IntPairAsDouble)` (Int, Int) = i
%   @bridge override /* method identity in X */
%   def identity(i: (Int, Int)): (Int, Int) = identity(i)
%   @bridge override /* method identity in Y */
%   def identity(i: `@repr(IntPairAsLong)` (Int, Int)): `@repr(IntPairAsLong)` (Int, Int) = identity(i)
% }
% \end{lstlisting-nobreak}
%
% And following the \coerce{} and \commit{} phases, class |Z| becomes:

The ensuing \bridge{} phase generates two bridge methods, one for each existing signature of the method |identity|:

\begin{lstlisting-nobreak}
class Z(t: `Double`) extends Y(...) {
  def identity(i: `Double`): `Double` = i
  @bridge override def identity(i: `(Int, Int)`): `(Int, Int)` = ...
  @bridge override def identity(i: `Long`): `Long` = ...
}
\end{lstlisting-nobreak}

%This more involved transformation, with two bridges and a total of 8 representation transformations (all of which were elided in the snippet), ensures the |identity| methods in both classes |X| and |Y| are correctly overridden.

In this case, the \bridge{} phase issues a warning that up-casting class |Z| to |Y| is suboptimal, as overriding requires transforming the representation in two steps (\S\ref{sec:ildl:signatures}).

\yannis{I'm not sure I understand the above.}

\subsubsection{Generics.}
% Another question that arises: Generics - whether the ADR transformation should transform generic containers. Example:
Another problem that arises when performing ad hoc programmer-driven transformations is how to transform the data representation in generic containers. Should the ADR transformation be allowed to change the data representation stored in a |List|? We illustrate the issue with an example:

\begin{lstlisting-nobreak}
def use1(list: List[(Int, Int)]): Unit = ...
adrt(IntPairAsLong) {
  def use2(list: List[(Int, Int)]): Unit = `use1(list)`
}
\end{lstlisting-nobreak}

% In the very particular case of list, it's okay, but not in the general case
In the specific case of the Scala immutable list, it would be possible to convert the |list| parameter of |use2| from type |List[Long]| to |List[(Int, Int)]| and call the |use1| method. This can be done by mapping over the list and transforming the representation of each element. However, this domain-specific knowledge of how to transform the container only applies to the immutable list, and not to other generic classes that may be encountered in the signature.

% Furthermore, there is an entire class of mutable containers which cannot be transformed
Furthermore, there is an entire class of containers for which this approach is incorrect: mutable containers. An invariant of mutable containers is that any elements changed will be visible to all the code that holds a reference to the cointainer. But duplicating the container itself and its elements (stored with a different representation) breaks this invariant: changes to one copy of the mutable container are not visible to its other copies, violating the invariant.

% We could use the transformation representation object to add container transformation rules, but in the current implementation we did not find an elegan and general solution.
Therefore, the approach we follow in the ADR transformation is to
preserve the high-level type inside generics.\footnote{An interesting
  future direction would be to allow the transformation description
  object to also designate transformations for generic containers.}
%, but, in the current implementation, we do not allow this. 
Thus, our example after the \commit{} phase will be:

\begin{lstlisting-nobreak}
def use1(list: List[(Int, Int)]): Unit = ...
def use2(list: List[(Int, Int)]): Unit = `use1(list)`
\end{lstlisting-nobreak}

Although the integer pair cannot be transformed inside the generic
container, it is possible to change the container representation
itself: we can define a separate (optimized) representation
specifically for |List[(Int, Int)]|. Further, since transformation
scopes for different high-level types can be nested, we can transform
|List[(Int, Int)]| and |(Int, Int)| simultaneously.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Optimizing Method Invocations}
\label{sec:ildl:semantics}

% Objects encapsulate data and executable code. So far, the focus has been on the data representation, but that's not all: we also care about accessing methods of the transformed object
When choosing a generic container, such as a pair or a list, programmers are usually motivated by the very flexible interface, which allows them to quickly achieve their goal by invoking the container's many convenience methods. The presentation so far focused on optimizing the data representation, but to obtain peak performance, the method invocations need to be transformed as well:

\begin{lstlisting-nobreak}
adtr(`IntPairComplexToLongComplex`) {
  val n = (0, 1)
  println(n.toString)
}
\end{lstlisting-nobreak}

% \subsubsection{Methods and Operators of the Transformed Object}

% The normal approach taken by the LDL transformation is unnecessarily conservative: it boxes the value back and calls the method:
When handling method calls, the default LDL behavior is very conservative: it encodes the transformed representation back to its high-level type, which exposes the method, and then invokes it. This produces sub-optimal code:

\begin{lstlisting-nobreak}
val n: Long = ...
println(IntPairComplexToLongComplex.`fromRepr`(n).toString)
\end{lstlisting-nobreak}

% However, it also features extension methods, which are more efficient. However, these methods have to be added manually to the transformation description object to be used by the ADR transformation:
To optimize such cases, the LDL transformation can use extension methods, when they are available. For example, assuming the |extension_toString| exists in the transformation description object, the example can be transformed to:

\begin{lstlisting-nobreak}
val n: Long = ...
println(IntPairComplexToLongComplex.`extension_toString`(n))
\end{lstlisting-nobreak}

This avoids the costly pair object creation that slows down execution and inflates the heap requirements. In practice, the ADR transformation will look up the |extension_toString| method, and, in case it is not present, will warn the programmer and proceed with decoding the representation type so the dynamically dispatched method can be used.

% implicitly added methods + parameters
\subsubsection{Methods added via implicit conversions,} such as the multiplication operator |*| in the original example, add another layer of complexity:

\begin{lstlisting-nobreak}
adtr(`IntPairComplexToLongComplex`) {
  val n1 = (0, 1)
  val n2 = n1 * n1
}
\end{lstlisting-nobreak}

First, they wrap the original value in a new object, which exposes the multiplication operator, and then invoke this method:

\begin{lstlisting-nobreak}
adtr(IntPairComplexToLongComple) {
  val n1: (Int, Int) = (0, 1)
  val n2: (Int, Int) = `intPairIsComplex(n1)` * n1
}
\end{lstlisting-nobreak}

Clearly, this is a costly pattern, creating at least the pair and the wrapper object. To optimize it, the ADR transformation looks for an extension method in the transformation description object that corresponds to combining the implicit method and the operator. In practice, the name of the extension method will encode the implicit conversion and the operator, but, for simplicity, let us assume its name is |extension_*|.

There are a two restrictions on the |extension_*| method: it is required to take exactly one extra parameter compared to the |*| operator, which acts as the receiver of the extension method call, and the types of its parameters must match the types of the |*| parameters. This would produce the signature:

\begin{lstlisting-nobreak}
def extension_*(recv: `@repr(...) (Int, Int)`, n2: `(Int, Int)`): `(Int, Int)`
\end{lstlisting-nobreak}

However, this is clearly inefficient: it requires decoding the second parameter and encoding the result of the computation, producing two redundant pairs of integers on the heap. To avoid this, we relax the parameter type constraint: |extension_*|'s parameter types need to match the |*| parameter types, modulo the |@repr| annotation:

\begin{lstlisting-nobreak}
def extension_*(recv: `@repr (Int, Int)`,  n2: `@repr (Int, Int)`): `@repr (Int, Int)`
\end{lstlisting-nobreak}

Replacing this method in the compiled tree, after the \commit{} phase, produces the following code:

\begin{lstlisting-nobreak}
val n1: Long = IntPairComplexToLongComplex.toRepr((0, 1))
val n2: Long = `extension_*(n1, n1)`
\end{lstlisting-nobreak}

This code is much more efficient: the complex multiplication does not require any object allocation at all! Yet, there is still a snag.

% constructors
\subsubsection{Constructors} create heap objects before they can be encoded in the representation type. Instead of allowing them to run, the ADR transformation intercepts and rewrites their invocations to extension methods that output the representation type directly. Using this feature on the code above, we get:

\begin{lstlisting-nobreak}
val n1: Long = IntPairComplexToLongComplex.`toRepr_ctor(0, 1)`
val n2: Long = extension_*(n1, n1)
\end{lstlisting-nobreak}

Notice the integers are now passed as arguments to the extension |toRepr_ctor| method, by value. This completes this scope's transformation, allowing it to execute without allocating any heap object at all.



